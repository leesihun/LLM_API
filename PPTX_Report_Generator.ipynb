{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Warpage Analysis - PowerPoint Report Generator\n",
    "\n",
    "This notebook generates a comprehensive PowerPoint presentation from warpage statistics data.\n",
    "\n",
    "**Features:**\n",
    "- **Multi-file support**: Load and compare multiple datasets\n",
    "- Loads data via LLM API (follows API_examples.ipynb pattern)\n",
    "- Creates beautiful visualizations using matplotlib/seaborn\n",
    "- Generates professional PPTX with python-pptx\n",
    "- Includes statistical analysis, trends, distributions, PCA, outliers, and recommendations\n",
    "- Automatic dataset comparison when multiple files are provided\n",
    "\n",
    "**Required Packages:**\n",
    "```bash\n",
    "pip install python-pptx matplotlib seaborn pandas numpy scipy scikit-learn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install python-pptx matplotlib seaborn pandas numpy scipy pillow -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Setup API Client (Following API_examples.ipynb Pattern)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "from pathlib import Path\n",
    "from typing import Iterator\n",
    "\n",
    "class LLMApiClient:\n",
    "    def __init__(self, base_url: str, timeout: float = 3600.0):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.token = None\n",
    "        self.timeout = httpx.Timeout(50.0, read=timeout, write=timeout, pool=timeout)\n",
    "\n",
    "    def _headers(self):\n",
    "        h = {}\n",
    "        if self.token:\n",
    "            h[\"Authorization\"] = f\"Bearer {self.token}\"\n",
    "        return h\n",
    "\n",
    "    def login(self, username: str, password: str):\n",
    "        r = httpx.post(f\"{self.base_url}/api/auth/login\", json={\n",
    "            \"username\": username, \"password\": password\n",
    "        }, timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        self.token = data[\"access_token\"]\n",
    "        return data\n",
    "\n",
    "    def list_models(self):\n",
    "        headers = {\"Authorization\": f\"Bearer {self.token}\"} if self.token else {}\n",
    "        r = httpx.get(f\"{self.base_url}/v1/models\", headers=headers, timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def chat_new(self, model: str, user_message: str, agent_type: str = \"auto\", files: list = None):\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"messages\": json.dumps(messages),\n",
    "            \"agent_type\": agent_type\n",
    "        }\n",
    "        \n",
    "        files_to_upload = []\n",
    "        if files:\n",
    "            for file_path in files:\n",
    "                f = open(file_path, \"rb\")\n",
    "                files_to_upload.append((\"files\", (Path(file_path).name, f)))\n",
    "        \n",
    "        try:\n",
    "            r = httpx.post(\n",
    "                f\"{self.base_url}/v1/chat/completions\",\n",
    "                data=data,\n",
    "                files=files_to_upload if files_to_upload else None,\n",
    "                headers=self._headers(),\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "            result = r.json()\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"], result[\"x_session_id\"]\n",
    "        finally:\n",
    "            for _, (_, f) in files_to_upload:\n",
    "                f.close()\n",
    "\n",
    "# Configuration\n",
    "API_BASE_URL = 'http://localhost:1007'\n",
    "USERNAME = \"leesihun\"\n",
    "PASSWORD = \"s.hun.lee\"\n",
    "\n",
    "# Initialize client\n",
    "client = LLMApiClient(API_BASE_URL, timeout=3600.0)\n",
    "print(f\"Client ready: {API_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Login and Get Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login\n",
    "login_result = client.login(USERNAME, PASSWORD)\n",
    "print(f\"Logged in as: {USERNAME}\")\n",
    "\n",
    "# Get available models\n",
    "models = client.list_models()\n",
    "MODEL = models[\"data\"][0][\"id\"]\n",
    "print(f\"Using model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Load Warpage Statistics Data via API\n",
    "\n",
    "**Configure your data files below** - supports single or multiple JSON files for comparative analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ========================================\n",
    "# CONFIGURATION: Define your data files\n",
    "# ========================================\n",
    "# Option 1: Single file\n",
    "# stats_paths = [Path(f\"data/uploads/{USERNAME}/20251013_stats.json\")]\n",
    "\n",
    "# Option 2: Multiple files for comparison\n",
    "stats_paths = [\n",
    "    Path(f\"data/uploads/{USERNAME}/20251013_stats.json\"),\n",
    "    # Path(f\"data/uploads/{USERNAME}/20251014_stats.json\"),\n",
    "    # Path(f\"data/uploads/{USERNAME}/20251015_stats.json\"),\n",
    "]\n",
    "\n",
    "print(f\"Loading {len(stats_paths)} data file(s)...\\n\")\n",
    "\n",
    "# ========================================\n",
    "# Load and combine all data files\n",
    "# ========================================\n",
    "all_dataframes = []\n",
    "dataset_metadata = []\n",
    "\n",
    "for idx, stats_path in enumerate(stats_paths, 1):\n",
    "    print(f\"[{idx}/{len(stats_paths)}] Loading: {stats_path.name}\")\n",
    "    \n",
    "    # Load JSON\n",
    "    with open(stats_path, 'r') as f:\n",
    "        warpage_data = json.load(f)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    temp_df = pd.DataFrame(warpage_data['files'])\n",
    "    \n",
    "    # Extract PCA components\n",
    "    temp_df['pc1'] = temp_df['pca'].apply(lambda x: x['pc1'])\n",
    "    temp_df['pc2'] = temp_df['pca'].apply(lambda x: x['pc2'])\n",
    "    \n",
    "    # Add metadata columns\n",
    "    temp_df['dataset_name'] = stats_path.stem  # Filename without extension\n",
    "    temp_df['dataset_index'] = idx\n",
    "    temp_df['source_file'] = str(stats_path)\n",
    "    \n",
    "    all_dataframes.append(temp_df)\n",
    "    \n",
    "    dataset_metadata.append({\n",
    "        'name': stats_path.stem,\n",
    "        'file_count': len(temp_df),\n",
    "        'source_pdf': warpage_data.get('source_pdf', 'N/A')\n",
    "    })\n",
    "    \n",
    "    print(f\"    ✓ Loaded {len(temp_df)} measurement files from {stats_path.stem}\")\n",
    "\n",
    "# Combine all datasets\n",
    "df = pd.concat(all_dataframes, ignore_index=True)\n",
    "\n",
    "# Add global file index for temporal analysis (across all datasets)\n",
    "df['file_index'] = range(1, len(df) + 1)\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"Total measurement files loaded: {len(df)}\")\n",
    "print(f\"Number of datasets: {len(stats_paths)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Display dataset summary\n",
    "print(\"Dataset Summary:\")\n",
    "for meta in dataset_metadata:\n",
    "    print(f\"  • {meta['name']}: {meta['file_count']} files (from {meta['source_pdf']})\")\n",
    "\n",
    "print(\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Statistical Analysis via API (Optional - for AI insights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the AI to analyze the data (following example #13 pattern)\n",
    "analysis_query = \"\"\"\n",
    "The attached files are warpage measurements in corresponding days.\n",
    "Upon the  warpage analysis data, provide a concise executive summary:\n",
    "\n",
    "1. Overall data quality assessment\n",
    "2. Key findings (2-3 bullet points)\n",
    "3. Files with potential quality issues (if any)\n",
    "4. Recommended actions (2-3 points)\n",
    "\n",
    "Keep the response under 200 words.\n",
    "\"\"\"\n",
    "\n",
    "# Pass all data files to the API\n",
    "ai_analysis, session_id = client.chat_new(\n",
    "    MODEL, \n",
    "    analysis_query, \n",
    "    agent_type=\"auto\",\n",
    "    files=[str(path) for path in stats_paths]  # Send all files\n",
    ")\n",
    "\n",
    "print(\"=== AI Executive Summary ===\")\n",
    "from IPython.display import display, Math, Latex\n",
    "display(Latex(ai_analysis))\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Setup Visualization Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from matplotlib import rcParams\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Professional color palette\n",
    "COLORS = {\n",
    "    'primary': '#1f77b4',      # Blue\n",
    "    'secondary': '#ff7f0e',    # Orange\n",
    "    'accent': '#2ca02c',       # Green\n",
    "    'warning': '#d62728',      # Red\n",
    "    'neutral': '#7f7f7f'       # Gray\n",
    "}\n",
    "\n",
    "# Set style\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"deep\")\n",
    "\n",
    "# High DPI for crisp images\n",
    "rcParams['figure.dpi'] = 300\n",
    "rcParams['savefig.dpi'] = 300\n",
    "rcParams['font.size'] = 10\n",
    "rcParams['axes.titlesize'] = 12\n",
    "rcParams['axes.labelsize'] = 10\n",
    "rcParams['xtick.labelsize'] = 9\n",
    "rcParams['ytick.labelsize'] = 9\n",
    "\n",
    "print(\"Visualization style configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate All Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output directory for charts\n",
    "output_dir = Path(\"temp_charts\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(f\"Saving charts to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Temporal Trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 1: Temporal trends (Mean, Median, Std over time)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "ax.plot(df['file_index'], df['mean'], label='Mean', linewidth=2, color=COLORS['primary'])\n",
    "ax.plot(df['file_index'], df['median'], label='Median', linewidth=2, color=COLORS['secondary'], linestyle='--')\n",
    "ax.fill_between(df['file_index'], \n",
    "                df['mean'] - df['std'], \n",
    "                df['mean'] + df['std'], \n",
    "                alpha=0.2, color=COLORS['primary'], label='±1 Std Dev')\n",
    "\n",
    "ax.set_xlabel('File Index (Temporal Sequence)')\n",
    "ax.set_ylabel('Warpage Value')\n",
    "ax.set_title('Temporal Trends: Mean, Median, and Variability', fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='best')\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'temporal_trends.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: temporal_trends.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Dataset Comparison (if multiple files loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 1b: Dataset comparison (only if multiple datasets loaded)\n",
    "if len(stats_paths) > 1:\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "    \n",
    "    # Group by dataset for comparison\n",
    "    dataset_summary = df.groupby('dataset_name').agg({\n",
    "        'mean': 'mean',\n",
    "        'std': 'mean',\n",
    "        'range': 'mean',\n",
    "        'kurtosis': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Plot 1: Mean comparison\n",
    "    axes[0, 0].bar(dataset_summary['dataset_name'], dataset_summary['mean'], \n",
    "                   color=COLORS['primary'], edgecolor='black', alpha=0.7)\n",
    "    axes[0, 0].set_title('Average Mean Warpage by Dataset', fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Mean Warpage')\n",
    "    axes[0, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 2: Std comparison\n",
    "    axes[0, 1].bar(dataset_summary['dataset_name'], dataset_summary['std'], \n",
    "                   color=COLORS['secondary'], edgecolor='black', alpha=0.7)\n",
    "    axes[0, 1].set_title('Average Std Dev by Dataset', fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Standard Deviation')\n",
    "    axes[0, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 3: Range comparison\n",
    "    axes[1, 0].bar(dataset_summary['dataset_name'], dataset_summary['range'], \n",
    "                   color=COLORS['accent'], edgecolor='black', alpha=0.7)\n",
    "    axes[1, 0].set_title('Average Range by Dataset', fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Range')\n",
    "    axes[1, 0].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Plot 4: Box plot comparison of means across datasets\n",
    "    dataset_groups = [df[df['dataset_name'] == name]['mean'].values for name in dataset_summary['dataset_name']]\n",
    "    bp = axes[1, 1].boxplot(dataset_groups, labels=dataset_summary['dataset_name'], patch_artist=True)\n",
    "    \n",
    "    # Color each box differently\n",
    "    palette = sns.color_palette(\"deep\", len(dataset_groups))\n",
    "    for patch, color in zip(bp['boxes'], palette):\n",
    "        patch.set_facecolor(color)\n",
    "        patch.set_alpha(0.7)\n",
    "    \n",
    "    axes[1, 1].set_title('Mean Distribution by Dataset', fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Mean Warpage')\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_dir / 'dataset_comparison.png', bbox_inches='tight', dpi=300)\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"✓ Saved: dataset_comparison.png\")\n",
    "else:\n",
    "    print(\"⊘ Skipped: dataset_comparison.png (single dataset mode)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 2: Distribution of key metrics (2x2 grid)\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Mean distribution\n",
    "axes[0, 0].hist(df['mean'], bins=15, color=COLORS['primary'], edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].axvline(df['mean'].mean(), color=COLORS['warning'], linestyle='--', linewidth=2, label=f\"Avg: {df['mean'].mean():.2f}\")\n",
    "axes[0, 0].set_title('Distribution of Mean Values', fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Mean Warpage')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# Std distribution\n",
    "axes[0, 1].hist(df['std'], bins=15, color=COLORS['secondary'], edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].axvline(df['std'].mean(), color=COLORS['warning'], linestyle='--', linewidth=2, label=f\"Avg: {df['std'].mean():.2f}\")\n",
    "axes[0, 1].set_title('Distribution of Standard Deviation', fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Std Dev')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].legend()\n",
    "\n",
    "# Skewness distribution\n",
    "axes[1, 0].hist(df['skewness'], bins=15, color=COLORS['accent'], edgecolor='black', alpha=0.7)\n",
    "axes[1, 0].axvline(df['skewness'].mean(), color=COLORS['warning'], linestyle='--', linewidth=2, label=f\"Avg: {df['skewness'].mean():.2f}\")\n",
    "axes[1, 0].set_title('Distribution of Skewness', fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Skewness')\n",
    "axes[1, 0].set_ylabel('Frequency')\n",
    "axes[1, 0].legend()\n",
    "\n",
    "# Kurtosis distribution\n",
    "axes[1, 1].hist(df['kurtosis'], bins=15, color=COLORS['neutral'], edgecolor='black', alpha=0.7)\n",
    "axes[1, 1].axvline(df['kurtosis'].mean(), color=COLORS['warning'], linestyle='--', linewidth=2, label=f\"Avg: {df['kurtosis'].mean():.2f}\")\n",
    "axes[1, 1].axvline(47, color='red', linestyle=':', linewidth=2, label=\"Outlier Threshold (47)\")\n",
    "axes[1, 1].set_title('Distribution of Kurtosis', fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Kurtosis')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "axes[1, 1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'distributions.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: distributions.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 Box Plot Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 3: Box plots for variability\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 5))\n",
    "\n",
    "# Min/Max/Range\n",
    "data_minmax = [df['min'], df['max'], df['range']]\n",
    "bp1 = axes[0].boxplot(data_minmax, labels=['Min', 'Max', 'Range'], patch_artist=True)\n",
    "for patch, color in zip(bp1['boxes'], [COLORS['primary'], COLORS['secondary'], COLORS['accent']]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[0].set_title('Min/Max/Range Analysis', fontweight='bold')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Mean/Median\n",
    "data_central = [df['mean'], df['median']]\n",
    "bp2 = axes[1].boxplot(data_central, labels=['Mean', 'Median'], patch_artist=True)\n",
    "for patch, color in zip(bp2['boxes'], [COLORS['primary'], COLORS['secondary']]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[1].set_title('Central Tendency', fontweight='bold')\n",
    "axes[1].set_ylabel('Value')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Std/Skewness/Kurtosis (normalized)\n",
    "data_dist = [df['std'], df['skewness']*10, df['kurtosis']/10]  # Scale for visibility\n",
    "bp3 = axes[2].boxplot(data_dist, labels=['Std', 'Skewness×10', 'Kurtosis÷10'], patch_artist=True)\n",
    "for patch, color in zip(bp3['boxes'], [COLORS['accent'], COLORS['warning'], COLORS['neutral']]):\n",
    "    patch.set_facecolor(color)\n",
    "    patch.set_alpha(0.7)\n",
    "axes[2].set_title('Distribution Metrics (Scaled)', fontweight='bold')\n",
    "axes[2].set_ylabel('Scaled Value')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'boxplots.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: boxplots.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4 PCA Scatter Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 4: PCA scatter plot\n",
    "fig, ax = plt.subplots(figsize=(10, 7))\n",
    "\n",
    "scatter = ax.scatter(df['pc1'], df['pc2'], \n",
    "                     c=df['file_index'], \n",
    "                     cmap='viridis', \n",
    "                     s=100, \n",
    "                     edgecolors='black', \n",
    "                     linewidth=0.5,\n",
    "                     alpha=0.8)\n",
    "\n",
    "# Annotate outliers (based on distance from center)\n",
    "pc1_mean, pc2_mean = df['pc1'].mean(), df['pc2'].mean()\n",
    "distances = np.sqrt((df['pc1'] - pc1_mean)**2 + (df['pc2'] - pc2_mean)**2)\n",
    "outlier_threshold = distances.quantile(0.95)\n",
    "outliers = df[distances > outlier_threshold]\n",
    "\n",
    "for _, row in outliers.iterrows():\n",
    "    ax.annotate(row['file_id'], \n",
    "                (row['pc1'], row['pc2']), \n",
    "                textcoords=\"offset points\", \n",
    "                xytext=(5, 5), \n",
    "                ha='left',\n",
    "                fontsize=7,\n",
    "                bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.5))\n",
    "\n",
    "cbar = plt.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('File Index (Time)', rotation=270, labelpad=20)\n",
    "\n",
    "ax.set_xlabel('PC1 (Principal Component 1)')\n",
    "ax.set_ylabel('PC2 (Principal Component 2)')\n",
    "ax.set_title('PCA Analysis: PC1 vs PC2 (Color: Temporal Sequence)', fontweight='bold', fontsize=14)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'pca_scatter.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: pca_scatter.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.5 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 5: Correlation heatmap\n",
    "numeric_cols = ['min', 'max', 'range', 'mean', 'median', 'std', 'skewness', 'kurtosis', 'pc1', 'pc2']\n",
    "corr_matrix = df[numeric_cols].corr()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "sns.heatmap(corr_matrix, \n",
    "            annot=True, \n",
    "            fmt='.2f', \n",
    "            cmap='coolwarm', \n",
    "            center=0,\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.8},\n",
    "            ax=ax)\n",
    "\n",
    "ax.set_title('Correlation Matrix: All Metrics', fontweight='bold', fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'correlation_heatmap.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: correlation_heatmap.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.6 Outlier Detection (Control Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 6: Control chart for outlier detection\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "mean_avg = df['mean'].mean()\n",
    "mean_std = df['mean'].std()\n",
    "\n",
    "# Plot mean values\n",
    "ax.plot(df['file_index'], df['mean'], marker='o', linewidth=1.5, markersize=4, color=COLORS['primary'], label='Mean Warpage')\n",
    "\n",
    "# Control limits (±3σ)\n",
    "ax.axhline(mean_avg, color='green', linestyle='-', linewidth=2, label=f'Center Line: {mean_avg:.2f}')\n",
    "ax.axhline(mean_avg + 3*mean_std, color='red', linestyle='--', linewidth=2, label=f'UCL (+3σ): {mean_avg + 3*mean_std:.2f}')\n",
    "ax.axhline(mean_avg - 3*mean_std, color='red', linestyle='--', linewidth=2, label=f'LCL (-3σ): {mean_avg - 3*mean_std:.2f}')\n",
    "\n",
    "# Shade warning zones (±2σ)\n",
    "ax.fill_between(df['file_index'], mean_avg - 2*mean_std, mean_avg + 2*mean_std, alpha=0.1, color='yellow')\n",
    "\n",
    "# Highlight out-of-control points\n",
    "outliers_upper = df[df['mean'] > mean_avg + 3*mean_std]\n",
    "outliers_lower = df[df['mean'] < mean_avg - 3*mean_std]\n",
    "ax.scatter(outliers_upper['file_index'], outliers_upper['mean'], color='red', s=100, zorder=5, marker='x', linewidths=3, label='Out of Control')\n",
    "ax.scatter(outliers_lower['file_index'], outliers_lower['mean'], color='red', s=100, zorder=5, marker='x', linewidths=3)\n",
    "\n",
    "ax.set_xlabel('File Index (Temporal Sequence)')\n",
    "ax.set_ylabel('Mean Warpage')\n",
    "ax.set_title('Control Chart: Mean Warpage with ±3σ Limits', fontweight='bold', fontsize=14)\n",
    "ax.legend(loc='best', fontsize=9)\n",
    "ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'control_chart.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: control_chart.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.7 Top vs Bottom Performers (Radar Chart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 7: Radar chart comparing best vs worst performers\n",
    "from math import pi\n",
    "\n",
    "# Define \"quality\" score (lower std = better, closer to median mean = better)\n",
    "df['quality_score'] = -df['std'] - abs(df['mean'] - df['mean'].median())\n",
    "\n",
    "# Get top 5 and bottom 5\n",
    "top5 = df.nlargest(5, 'quality_score')\n",
    "bottom5 = df.nsmallest(5, 'quality_score')\n",
    "\n",
    "# Metrics for radar chart (normalized to 0-1)\n",
    "metrics = ['mean', 'std', 'range', 'skewness', 'kurtosis']\n",
    "top5_avg = top5[metrics].mean()\n",
    "bottom5_avg = bottom5[metrics].mean()\n",
    "\n",
    "# Normalize\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(df[metrics])\n",
    "top5_norm = scaler.transform(top5[metrics]).mean(axis=0)\n",
    "bottom5_norm = scaler.transform(bottom5[metrics]).mean(axis=0)\n",
    "\n",
    "# Radar chart setup\n",
    "angles = [n / float(len(metrics)) * 2 * pi for n in range(len(metrics))]\n",
    "top5_norm = np.concatenate((top5_norm, [top5_norm[0]]))  # Close the circle\n",
    "bottom5_norm = np.concatenate((bottom5_norm, [bottom5_norm[0]]))\n",
    "angles += angles[:1]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8), subplot_kw=dict(polar=True))\n",
    "\n",
    "ax.plot(angles, top5_norm, 'o-', linewidth=2, label='Top 5 Files (Best Quality)', color=COLORS['accent'])\n",
    "ax.fill(angles, top5_norm, alpha=0.25, color=COLORS['accent'])\n",
    "\n",
    "ax.plot(angles, bottom5_norm, 'o-', linewidth=2, label='Bottom 5 Files (Worst Quality)', color=COLORS['warning'])\n",
    "ax.fill(angles, bottom5_norm, alpha=0.25, color=COLORS['warning'])\n",
    "\n",
    "ax.set_xticks(angles[:-1])\n",
    "ax.set_xticklabels(metrics, fontsize=10)\n",
    "ax.set_ylim(0, 1)\n",
    "ax.set_title('Radar Chart: Top 5 vs Bottom 5 Files\\n(Normalized Metrics)', fontweight='bold', fontsize=14, pad=20)\n",
    "ax.legend(loc='upper right', bbox_to_anchor=(1.3, 1.1))\n",
    "ax.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'radar_chart.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: radar_chart.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.8 Summary Statistics Table (as image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chart 8: Summary statistics table\n",
    "summary_stats = df[numeric_cols].describe().round(2)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.axis('tight')\n",
    "ax.axis('off')\n",
    "\n",
    "table = ax.table(cellText=summary_stats.values,\n",
    "                 rowLabels=summary_stats.index,\n",
    "                 colLabels=summary_stats.columns,\n",
    "                 cellLoc='center',\n",
    "                 loc='center',\n",
    "                 colWidths=[0.1]*len(summary_stats.columns))\n",
    "\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(9)\n",
    "table.scale(1, 2)\n",
    "\n",
    "# Color header row\n",
    "for i in range(len(summary_stats.columns)):\n",
    "    table[(0, i)].set_facecolor(COLORS['primary'])\n",
    "    table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "\n",
    "# Color row labels\n",
    "for i in range(len(summary_stats.index)):\n",
    "    table[(i+1, -1)].set_facecolor('#E8E8E8')\n",
    "    table[(i+1, -1)].set_text_props(weight='bold')\n",
    "\n",
    "ax.set_title('Summary Statistics: All Metrics', fontweight='bold', fontsize=14, pad=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(output_dir / 'summary_table.png', bbox_inches='tight', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Saved: summary_table.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate PowerPoint Presentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pptx import Presentation\n",
    "from pptx.util import Inches, Pt\n",
    "from pptx.enum.text import PP_ALIGN\n",
    "from pptx.dml.color import RGBColor\n",
    "from datetime import datetime\n",
    "\n",
    "# Create presentation\n",
    "prs = Presentation()\n",
    "prs.slide_width = Inches(10)\n",
    "prs.slide_height = Inches(7.5)\n",
    "\n",
    "print(\"Creating PowerPoint presentation...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Title Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide 1: Title\n",
    "slide = prs.slides.add_slide(prs.slide_layouts[6])  # Blank layout\n",
    "\n",
    "# Title\n",
    "title_box = slide.shapes.add_textbox(Inches(1), Inches(2.5), Inches(8), Inches(1))\n",
    "title_frame = title_box.text_frame\n",
    "title_frame.text = \"Warpage Analysis Report\"\n",
    "title_frame.paragraphs[0].font.size = Pt(44)\n",
    "title_frame.paragraphs[0].font.bold = True\n",
    "title_frame.paragraphs[0].font.color.rgb = RGBColor(31, 119, 180)\n",
    "title_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "\n",
    "# Subtitle (show dataset count if multiple)\n",
    "subtitle_text = f\"Statistical Analysis of {len(df)} Measurement Files\"\n",
    "if len(stats_paths) > 1:\n",
    "    subtitle_text += f\" ({len(stats_paths)} Datasets)\"\n",
    "\n",
    "subtitle_box = slide.shapes.add_textbox(Inches(1), Inches(3.8), Inches(8), Inches(0.6))\n",
    "subtitle_frame = subtitle_box.text_frame\n",
    "subtitle_frame.text = subtitle_text\n",
    "subtitle_frame.paragraphs[0].font.size = Pt(24)\n",
    "subtitle_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "\n",
    "# Date\n",
    "date_box = slide.shapes.add_textbox(Inches(1), Inches(4.6), Inches(8), Inches(0.4))\n",
    "date_frame = date_box.text_frame\n",
    "date_frame.text = f\"Report Date: {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "date_frame.paragraphs[0].font.size = Pt(14)\n",
    "date_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "date_frame.paragraphs[0].font.italic = True\n",
    "\n",
    "print(\"✓ Slide 1: Title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Executive Summary Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide 2: Executive Summary\n",
    "slide = prs.slides.add_slide(prs.slide_layouts[6])\n",
    "\n",
    "# Title\n",
    "title = slide.shapes.add_textbox(Inches(0.5), Inches(0.3), Inches(9), Inches(0.6))\n",
    "title.text_frame.text = \"Executive Summary\"\n",
    "title.text_frame.paragraphs[0].font.size = Pt(32)\n",
    "title.text_frame.paragraphs[0].font.bold = True\n",
    "title.text_frame.paragraphs[0].font.color.rgb = RGBColor(31, 119, 180)\n",
    "\n",
    "# Key metrics boxes\n",
    "metrics_data = [\n",
    "    (\"Total Files\", str(len(df)), COLORS['primary']),\n",
    "    (\"Avg Mean Warpage\", f\"{df['mean'].mean():.2f}\", COLORS['secondary']),\n",
    "    (\"Avg Std Dev\", f\"{df['std'].mean():.2f}\", COLORS['accent']),\n",
    "    (\"Outliers (Kurtosis>47)\", str(len(df[df['kurtosis'] > 47])), COLORS['warning'])\n",
    "]\n",
    "\n",
    "x_start = 0.5\n",
    "for i, (label, value, color) in enumerate(metrics_data):\n",
    "    # Box background\n",
    "    box = slide.shapes.add_shape(\n",
    "        1,  # Rectangle\n",
    "        Inches(x_start + i*2.3), Inches(1.2),\n",
    "        Inches(2), Inches(1.2)\n",
    "    )\n",
    "    box.fill.solid()\n",
    "    box.fill.fore_color.rgb = RGBColor(*tuple(int(color.lstrip('#')[i:i+2], 16) for i in (0, 2, 4)))\n",
    "    box.line.color.rgb = RGBColor(255, 255, 255)\n",
    "    \n",
    "    # Value text\n",
    "    value_box = slide.shapes.add_textbox(\n",
    "        Inches(x_start + i*2.3), Inches(1.4),\n",
    "        Inches(2), Inches(0.5)\n",
    "    )\n",
    "    value_box.text_frame.text = value\n",
    "    value_box.text_frame.paragraphs[0].font.size = Pt(28)\n",
    "    value_box.text_frame.paragraphs[0].font.bold = True\n",
    "    value_box.text_frame.paragraphs[0].font.color.rgb = RGBColor(255, 255, 255)\n",
    "    value_box.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "    \n",
    "    # Label text\n",
    "    label_box = slide.shapes.add_textbox(\n",
    "        Inches(x_start + i*2.3), Inches(1.95),\n",
    "        Inches(2), Inches(0.3)\n",
    "    )\n",
    "    label_box.text_frame.text = label\n",
    "    label_box.text_frame.paragraphs[0].font.size = Pt(11)\n",
    "    label_box.text_frame.paragraphs[0].font.color.rgb = RGBColor(255, 255, 255)\n",
    "    label_box.text_frame.paragraphs[0].alignment = PP_ALIGN.CENTER\n",
    "\n",
    "# AI Summary (if available)\n",
    "summary_box = slide.shapes.add_textbox(Inches(0.5), Inches(2.8), Inches(9), Inches(3.5))\n",
    "text_frame = summary_box.text_frame\n",
    "text_frame.word_wrap = True\n",
    "p = text_frame.paragraphs[0]\n",
    "p.text = \"Key Findings:\\n\\n\" + (ai_analysis if 'ai_analysis' in locals() else \"Data loaded successfully. Statistical analysis complete.\")\n",
    "p.font.size = Pt(14)\n",
    "p.line_spacing = 1.3\n",
    "\n",
    "print(\"✓ Slide 2: Executive Summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 Chart Slides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to add chart slide\n",
    "def add_chart_slide(prs, title_text, image_path, description=\"\"):\n",
    "    slide = prs.slides.add_slide(prs.slide_layouts[6])\n",
    "    \n",
    "    # Title\n",
    "    title = slide.shapes.add_textbox(Inches(0.5), Inches(0.3), Inches(9), Inches(0.5))\n",
    "    title.text_frame.text = title_text\n",
    "    title.text_frame.paragraphs[0].font.size = Pt(28)\n",
    "    title.text_frame.paragraphs[0].font.bold = True\n",
    "    title.text_frame.paragraphs[0].font.color.rgb = RGBColor(31, 119, 180)\n",
    "    \n",
    "    # Image\n",
    "    img_height = 5.5 if not description else 4.5\n",
    "    slide.shapes.add_picture(str(image_path), Inches(0.5), Inches(1), width=Inches(9), height=Inches(img_height))\n",
    "    \n",
    "    # Description (if provided)\n",
    "    if description:\n",
    "        desc_box = slide.shapes.add_textbox(Inches(0.5), Inches(5.7), Inches(9), Inches(1.2))\n",
    "        desc_box.text_frame.text = description\n",
    "        desc_box.text_frame.paragraphs[0].font.size = Pt(11)\n",
    "        desc_box.text_frame.word_wrap = True\n",
    "\n",
    "# Slide 3: Temporal Trends\n",
    "add_chart_slide(\n",
    "    prs,\n",
    "    \"Temporal Trends\",\n",
    "    output_dir / 'temporal_trends.png',\n",
    "    \"This chart shows how mean warpage values change over time (file sequence). The shaded area represents ±1 standard deviation, indicating variability around the mean.\"\n",
    ")\n",
    "print(\"✓ Slide 3: Temporal Trends\")\n",
    "\n",
    "# Slide 3b: Dataset Comparison (only if multiple datasets)\n",
    "if len(stats_paths) > 1 and (output_dir / 'dataset_comparison.png').exists():\n",
    "    add_chart_slide(\n",
    "        prs,\n",
    "        \"Dataset Comparison\",\n",
    "        output_dir / 'dataset_comparison.png',\n",
    "        f\"Comparative analysis across {len(stats_paths)} datasets. Bar charts show average values by dataset, while box plots reveal distribution patterns and outliers within each dataset.\"\n",
    "    )\n",
    "    print(\"✓ Slide 3b: Dataset Comparison\")\n",
    "\n",
    "# Slide 4: Distributions\n",
    "add_chart_slide(\n",
    "    prs,\n",
    "    \"Distribution Analysis\",\n",
    "    output_dir / 'distributions.png',\n",
    "    f\"Distribution of key statistical metrics across all {len(df)} files. Red dashed lines indicate mean values. The kurtosis chart shows the outlier threshold at 47.\"\n",
    ")\n",
    "print(\"✓ Slide 4: Distribution Analysis\")\n",
    "\n",
    "# Slide 5: Box Plots\n",
    "add_chart_slide(\n",
    "    prs,\n",
    "    \"Variability Analysis\",\n",
    "    output_dir / 'boxplots.png',\n",
    "    \"Box plots show the spread and quartiles of key metrics. The boxes represent the interquartile range (IQR), with whiskers extending to 1.5×IQR.\"\n",
    ")\n",
    "print(\"✓ Slide 5: Box Plots\")\n",
    "\n",
    "# Slide 6: PCA\n",
    "add_chart_slide(\n",
    "    prs,\n",
    "    \"PCA Analysis\",\n",
    "    output_dir / 'pca_scatter.png',\n",
    "    \"Principal Component Analysis (PCA) reduces dimensionality to visualize clustering patterns. Color gradient represents temporal sequence. Outliers are labeled.\"\n",
    ")\n",
    "print(\"✓ Slide 6: PCA Analysis\")\n",
    "\n",
    "# Slide 7: Correlation\n",
    "add_chart_slide(\n",
    "    prs,\n",
    "    \"Correlation Matrix\",\n",
    "    output_dir / 'correlation_heatmap.png',\n",
    "    \"Correlation coefficients between all metrics. Values close to ±1 indicate strong relationships (blue=negative, red=positive).\"\n",
    ")\n",
    "print(\"✓ Slide 7: Correlation Heatmap\")\n",
    "\n",
    "# Slide 8: Control Chart\n",
    "add_chart_slide(\n",
    "    prs,\n",
    "    \"Outlier Detection (Control Chart)\",\n",
    "    output_dir / 'control_chart.png',\n",
    "    \"Statistical process control chart with ±3σ limits. Points marked with 'X' are out of control and require investigation.\"\n",
    ")\n",
    "print(\"✓ Slide 8: Control Chart\")\n",
    "\n",
    "# Slide 9: Radar Chart\n",
    "add_chart_slide(\n",
    "    prs,\n",
    "    \"Top vs Bottom Performers\",\n",
    "    output_dir / 'radar_chart.png',\n",
    "    \"Comparison of top 5 files (best quality) vs bottom 5 (worst quality) across normalized metrics. Larger area indicates higher values.\"\n",
    ")\n",
    "print(\"✓ Slide 9: Radar Chart\")\n",
    "\n",
    "# Slide 10: Summary Table\n",
    "add_chart_slide(\n",
    "    prs,\n",
    "    \"Summary Statistics\",\n",
    "    output_dir / 'summary_table.png',\n",
    "    \"Descriptive statistics for all metrics: count, mean, std, min, quartiles (25%, 50%, 75%), and max values.\"\n",
    ")\n",
    "print(\"✓ Slide 10: Summary Table\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.4 Recommendations Slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Slide 11: Recommendations\n",
    "slide = prs.slides.add_slide(prs.slide_layouts[6])\n",
    "\n",
    "# Title\n",
    "title = slide.shapes.add_textbox(Inches(0.5), Inches(0.3), Inches(9), Inches(0.6))\n",
    "title.text_frame.text = \"Recommendations & Next Steps\"\n",
    "title.text_frame.paragraphs[0].font.size = Pt(32)\n",
    "title.text_frame.paragraphs[0].font.bold = True\n",
    "title.text_frame.paragraphs[0].font.color.rgb = RGBColor(31, 119, 180)\n",
    "\n",
    "# Recommendations\n",
    "recommendations = [\n",
    "    (\"Quality Control\", [\n",
    "        f\"Investigate {len(df[df['kurtosis'] > 47])} files with extreme kurtosis (>47)\",\n",
    "        \"Review files marked as 'out of control' in the control chart\",\n",
    "        \"Establish tighter control limits based on current process capability\"\n",
    "    ]),\n",
    "    (\"Process Improvement\", [\n",
    "        f\"Current mean warpage: {df['mean'].mean():.2f} (Target: closer to 0)\",\n",
    "        f\"Reduce variability: Avg Std Dev = {df['std'].mean():.2f}\",\n",
    "        \"Implement corrective actions for bottom 5 performers\"\n",
    "    ]),\n",
    "    (\"Monitoring\", [\n",
    "        \"Continue tracking PCA trends for early anomaly detection\",\n",
    "        \"Set up automated alerts for files exceeding ±3σ limits\",\n",
    "        \"Conduct root cause analysis on temporal patterns\"\n",
    "    ])\n",
    "]\n",
    "\n",
    "y_pos = 1.2\n",
    "for section, items in recommendations:\n",
    "    # Section header\n",
    "    header = slide.shapes.add_textbox(Inches(0.8), Inches(y_pos), Inches(8.5), Inches(0.4))\n",
    "    header.text_frame.text = section\n",
    "    header.text_frame.paragraphs[0].font.size = Pt(18)\n",
    "    header.text_frame.paragraphs[0].font.bold = True\n",
    "    header.text_frame.paragraphs[0].font.color.rgb = RGBColor(255, 127, 14)\n",
    "    \n",
    "    y_pos += 0.5\n",
    "    \n",
    "    # Bullet points\n",
    "    for item in items:\n",
    "        bullet = slide.shapes.add_textbox(Inches(1.2), Inches(y_pos), Inches(8), Inches(0.3))\n",
    "        bullet.text_frame.text = f\"• {item}\"\n",
    "        bullet.text_frame.paragraphs[0].font.size = Pt(12)\n",
    "        y_pos += 0.35\n",
    "    \n",
    "    y_pos += 0.2\n",
    "\n",
    "print(\"✓ Slide 11: Recommendations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.5 Save PowerPoint File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the presentation\n",
    "output_pptx = Path(f\"Warpage_Analysis_Report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pptx\")\n",
    "prs.save(str(output_pptx))\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"PowerPoint report generated successfully!\")\n",
    "print(f\"File: {output_pptx}\")\n",
    "print(f\"Size: {output_pptx.stat().st_size / 1024:.2f} KB\")\n",
    "print(f\"Total slides: {len(prs.slides)}\")\n",
    "print(f\"{'='*80}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Cleanup Temporary Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Clean up temporary chart files\n",
    "import shutil\n",
    "\n",
    "cleanup = input(\"Delete temporary chart files? (y/n): \")\n",
    "if cleanup.lower() == 'y':\n",
    "    shutil.rmtree(output_dir)\n",
    "    print(f\"✓ Cleaned up {output_dir}\")\n",
    "else:\n",
    "    print(f\"Temporary charts preserved in: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary\n",
    "\n",
    "**Report Generation Complete!**\n",
    "\n",
    "This notebook has:\n",
    "1. ✅ Connected to the LLM API (following API_examples.ipynb pattern)\n",
    "2. ✅ Loaded warpage statistics data from JSON (supports **multiple files**)\n",
    "3. ✅ Generated 8-9 professional visualizations (9 if multiple datasets)\n",
    "4. ✅ Created an 11-12 slide PowerPoint presentation with:\n",
    "   - Title slide (with dataset count)\n",
    "   - Executive summary with key metrics\n",
    "   - Temporal trends analysis\n",
    "   - **Dataset comparison** (if multiple files provided)\n",
    "   - Distribution analysis (4 metrics)\n",
    "   - Box plot variability analysis\n",
    "   - PCA scatter plot with outlier detection\n",
    "   - Correlation heatmap\n",
    "   - Control chart for quality control\n",
    "   - Radar chart comparing top/bottom performers\n",
    "   - Summary statistics table\n",
    "   - Recommendations and next steps\n",
    "\n",
    "**Multi-File Support:**\n",
    "- Configure `stats_paths` in cell 8 to load multiple JSON files\n",
    "- Automatic dataset comparison charts when >1 file is loaded\n",
    "- All analysis combines data from all datasets\n",
    "- Dataset metadata tracked and displayed\n",
    "\n",
    "**Next Steps:**\n",
    "- Open the generated .pptx file\n",
    "- Customize branding/colors as needed\n",
    "- Add company logo\n",
    "- Present to stakeholders\n",
    "\n",
    "**To run this notebook again:**\n",
    "```bash\n",
    "jupyter notebook PPTX_Report_Generator.ipynb\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
