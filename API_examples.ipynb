{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM API – End-to-End Examples (Single Notebook)\n",
    "\n",
    "This notebook shows a minimal client and step-by-step examples for:\n",
    "\n",
    "1. Create a new account\n",
    "2. Login\n",
    "3. Change models (admin privilege example)\n",
    "4. Start a new chat and get a response\n",
    "5. Continue a chat\n",
    "6. See chat history\n",
    "7. Websearch with agentic tool selection\n",
    "8. Agentic math calculation (LLM decides to use math tool)\n",
    "9. Sequential reasoning with ReAct agent (step-by-step thinking)\n",
    "10. Plan-and-Execute agent (parallel tool usage)\n",
    "11. Auto agent selection (smart router picks best agent)\n",
    "12. Complex JSON data analysis\n",
    "13. RAG: Upload and query Excel files\n",
    "\n",
    "Set your API base URL below if different from the default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install httpx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_BASE_URL = \"http://127.0.0.1:8000\"\n",
    "print(\"Using:\", API_BASE_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "\n",
    "class LLMApiClient:\n",
    "    def __init__(self, base_url: str, timeout: float = 300.0):\n",
    "        \"\"\"\n",
    "        Initialize the LLM API client.\n",
    "\n",
    "        Args:\n",
    "            base_url: API base URL\n",
    "            timeout: Request timeout in seconds (default: 300s/5min for LLM requests)\n",
    "        \"\"\"\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.token = None\n",
    "        # Create timeout config: 10s for connect, custom timeout for read/write/pool\n",
    "        self.timeout = httpx.Timeout(50.0, read=timeout, write=timeout, pool=timeout)\n",
    "\n",
    "    def _headers(self):\n",
    "        h = {\"Content-Type\": \"application/json\"}\n",
    "        if self.token:\n",
    "            h[\"Authorization\"] = f\"Bearer {self.token}\"\n",
    "        return h\n",
    "\n",
    "    def signup(self, username: str, password: str, role: str = \"guest\"):\n",
    "        r = httpx.post(f\"{self.base_url}/api/auth/signup\", json={\n",
    "            \"username\": username, \"password\": password, \"role\": role\n",
    "        }, timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def login(self, username: str, password: str):\n",
    "        r = httpx.post(f\"{self.base_url}/api/auth/login\", json={\n",
    "            \"username\": username, \"password\": password\n",
    "        }, timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        self.token = data[\"access_token\"]\n",
    "        return data\n",
    "\n",
    "    def list_models(self):\n",
    "        r = httpx.get(f\"{self.base_url}/v1/models\", headers=self._headers(), timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def change_model(self, model: str):\n",
    "        r = httpx.post(f\"{self.base_url}/api/admin/model\", json={\"model\": model}, headers=self._headers(), timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def chat_new(self, model: str, user_message: str, agent_type: str = \"auto\"):\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": user_message}],\n",
    "            \"agent_type\": agent_type\n",
    "        }\n",
    "        # Use the longer timeout for chat requests\n",
    "        r = httpx.post(f\"{self.base_url}/v1/chat/completions\", json=payload, headers=self._headers(), timeout=self.timeout)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"], data[\"x_session_id\"]\n",
    "\n",
    "    def chat_continue(self, model: str, session_id: str, user_message: str, agent_type: str = \"auto\"):\n",
    "        payload = {\n",
    "            \"model\": model,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": user_message}],\n",
    "            \"session_id\": session_id,\n",
    "            \"agent_type\": agent_type\n",
    "        }\n",
    "        # Use the longer timeout for chat requests\n",
    "        r = httpx.post(f\"{self.base_url}/v1/chat/completions\", json=payload, headers=self._headers(), timeout=self.timeout)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        return data[\"choices\"][0][\"message\"][\"content\"], data[\"x_session_id\"]\n",
    "\n",
    "    def chat_sessions(self):\n",
    "        r = httpx.get(f\"{self.base_url}/api/chat/sessions\", headers=self._headers(), timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()[\"sessions\"]\n",
    "\n",
    "    def chat_history(self, session_id: str):\n",
    "        r = httpx.get(f\"{self.base_url}/api/chat/history/{session_id}\", headers=self._headers(), timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()[\"messages\"]\n",
    "\n",
    "    def tools(self):\n",
    "        r = httpx.get(f\"{self.base_url}/api/tools/list\", headers=self._headers(), timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()[\"tools\"]\n",
    "\n",
    "    def math(self, expression: str):\n",
    "        r = httpx.post(f\"{self.base_url}/api/tools/math\", json={\"expression\": expression}, headers=self._headers(), timeout=30.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()[\"result\"]\n",
    "\n",
    "    def websearch(self, query: str, max_results: int = 5):\n",
    "        r = httpx.post(f\"{self.base_url}/api/tools/websearch\", json={\"query\": query, \"max_results\": max_results}, headers=self._headers(), timeout=60.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()[\"results\"]\n",
    "\n",
    "    def answer_from_json(self, model: str, json_blob: dict, question: str):\n",
    "        prompt = f\"Given this JSON: {json_blob}\\nAnswer: {question}\"\n",
    "        return self.chat_new(model, prompt)[0]\n",
    "\n",
    "client = LLMApiClient(API_BASE_URL, timeout=3000.0)  # 5 minute timeout\n",
    "print(\"Client ready with 3000s timeout for chat requests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Create a new account\n",
    "username = \"leesihun\"\n",
    "password = \"s.hun.lee\"\n",
    "client.signup(username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Login\n",
    "login = client.login(username, password)\n",
    "login\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Change models (admin only) – optional\n",
    "client.login(\"admin\", \"administrator\")\n",
    "client.change_model(\"gemma3:12b\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List models (OpenAI-compatible)\n",
    "models = client.list_models()\n",
    "models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Start a new chat and get a response\n",
    "MODEL = models[\"data\"][0][\"id\"]\n",
    "reply, session_id = client.chat_new(MODEL, \"Hello! Give me a short haiku about autumn.\")\n",
    "reply, session_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Continue a chat\n",
    "reply2, _ = client.chat_continue(MODEL, session_id, \"Now do one about winter.\")\n",
    "reply2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) See chat history\n",
    "client.chat_sessions(), client.chat_history(session_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Websearch with agentic tool selection\n",
    "# Let the agent decide to use the web search tool\n",
    "client.login(\"leesihun\", \"s.hun.lee\")\n",
    "search_query = \"Search the web and tell me who is SiHun Lee, Ph. D. Include sources.\"\n",
    "search_reply, _ = client.chat_new(MODEL, search_query)\n",
    "print(\"Websearch Response:\")\n",
    "print(search_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Agentic tool usage - Let the LLM decide which tool to use\n",
    "# Simple math question (agent will automatically use math_calculator tool)\n",
    "math_reply, _ = client.chat_new(MODEL, \"What is 11.951 divided by 3.751? Please calculate this precisely.\")\n",
    "print(\"Math Question Response:\")\n",
    "from IPython.display import display, Math, Latex\n",
    "display(Latex(math_reply))\n",
    "print(math_reply)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) Sequential reasoning with ReAct agent\n",
    "# This triggers the ReAct agent because it requires step-by-step thinking\n",
    "sequential_query = \"\"\"\n",
    "First, search the web to find the current population of Tokyo.\n",
    "Then, calculate what 15% of that population would be.\n",
    "Finally, tell me the result.\n",
    "Think hard, try to answer to best of your knowledge\n",
    "\"\"\"\n",
    "react_reply, _ = client.chat_new(MODEL, sequential_query, agent_type=\"react\")\n",
    "print(\"Sequential Reasoning (ReAct) Response:\")\n",
    "print(react_reply)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Plan-and-Execute agent with multiple tools\n",
    "# This triggers Plan-and-Execute agent because it uses \"and\" for parallel tasks\n",
    "parallel_query = \"\"\"\n",
    "Search for the latest news about artificial intelligence AND\n",
    "calculate the result of (100 * 0.15 + 25) / 2 AND\n",
    "tell me what you found.\n",
    "\"\"\"\n",
    "plan_reply, _ = client.chat_new(MODEL, parallel_query, agent_type=\"plan_execute\")\n",
    "print(\"Plan-and-Execute (Parallel) Response:\")\n",
    "print(plan_reply)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Auto agent selection - Let the router decide\n",
    "# The smart router will analyze the query and pick the best agent\n",
    "auto_query = \"If the capital of France has a population of 2.1 million, and we need to allocate 500 euros per person for a project, what's the total budget needed? First search for the actual population, then calculate.\"\n",
    "auto_reply, _ = client.chat_new(MODEL, auto_query, agent_type=\"auto\")\n",
    "print(\"Auto Agent Selection Response:\")\n",
    "print(auto_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Complex JSON data analysis\n",
    "# Create a realistic e-commerce dataset\n",
    "complex_json = {\n",
    "    \"company\": \"TechMart Inc\",\n",
    "    \"quarter\": \"Q3 2025\",\n",
    "    \"departments\": [\n",
    "        {\n",
    "            \"name\": \"Electronics\",\n",
    "            \"employees\": 45,\n",
    "            \"sales\": [\n",
    "                {\"product\": \"Laptop\", \"units_sold\": 320, \"price\": 1200, \"revenue\": 384000},\n",
    "                {\"product\": \"Smartphone\", \"units_sold\": 856, \"price\": 800, \"revenue\": 684800},\n",
    "                {\"product\": \"Tablet\", \"units_sold\": 142, \"price\": 500, \"revenue\": 71000}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Home Appliances\",\n",
    "            \"employees\": 32,\n",
    "            \"sales\": [\n",
    "                {\"product\": \"Refrigerator\", \"units_sold\": 89, \"price\": 1500, \"revenue\": 133500},\n",
    "                {\"product\": \"Washing Machine\", \"units_sold\": 124, \"price\": 900, \"revenue\": 111600},\n",
    "                {\"product\": \"Microwave\", \"units_sold\": 267, \"price\": 200, \"revenue\": 53400}\n",
    "            ]\n",
    "        },\n",
    "        {\n",
    "            \"name\": \"Furniture\",\n",
    "            \"employees\": 28,\n",
    "            \"sales\": [\n",
    "                {\"product\": \"Desk\", \"units_sold\": 178, \"price\": 450, \"revenue\": 80100},\n",
    "                {\"product\": \"Chair\", \"units_sold\": 432, \"price\": 150, \"revenue\": 64800},\n",
    "                {\"product\": \"Bookshelf\", \"units_sold\": 95, \"price\": 300, \"revenue\": 28500}\n",
    "            ]\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Ask the LLM to analyze this complex data structure\n",
    "analysis_query = \"\"\"\n",
    "Based on this company data, please analyze and tell me:\n",
    "1. Which department has the highest total revenue?\n",
    "2. What is the average revenue per employee across all departments?\n",
    "3. Which single product generated the most revenue?\n",
    "4. Calculate the total units sold across all departments.\n",
    "\"\"\"\n",
    "\n",
    "json_reply, _ = client.chat_new(MODEL, f\"Here is the data:\\n{complex_json}\\n\\n{analysis_query}\")\n",
    "print(\"Complex JSON Analysis Response:\")\n",
    "print(json_reply)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload (optional): use API /api/files/upload via requests with your JWT if needed.\n",
    "# Here we assume files are saved server-side and we just trigger indexing by calling the upload API or reading directly if exposed.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Example local paths on server side (adjust if needed)\n",
    "username = username  # from earlier cell\n",
    "pos_path = Path(f\"data/uploads/{username}/폴드 긍정.xlsx\")\n",
    "neg_path = Path(f\"data/uploads/{username}/폴드 부정.xlsx\")\n",
    "\n",
    "print(pos_path.exists(), neg_path.exists())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If files exist, upload via API (to ensure user-scoped indexing)\n",
    "headers = {\"Authorization\": f\"Bearer {client.token}\"}\n",
    "\n",
    "def upload_file(path: Path):\n",
    "    files = {\"file\": (path.name, open(path, \"rb\"), \"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\")}\n",
    "    r = httpx.post(f\"{API_BASE_URL}/api/files/upload\", headers=headers, files=files)\n",
    "    r.raise_for_status()\n",
    "    return r.json()\n",
    "\n",
    "uploads = []\n",
    "if pos_path.exists():\n",
    "    uploads.append(upload_file(pos_path))\n",
    "if neg_path.exists():\n",
    "    uploads.append(upload_file(neg_path))\n",
    "\n",
    "uploads\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query RAG across all indexed docs\n",
    "r = httpx.get(f\"{API_BASE_URL}/api/tools/rag/search\", params={\"query\": \"폴드에 대한 긍정/부정 기준을 요약해줘\", \"top_k\": 5}, headers=headers)\n",
    "r.raise_for_status()\n",
    "r.json()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
