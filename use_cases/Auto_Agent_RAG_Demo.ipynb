{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# RAG ReAct Loop Demo\n\nThis notebook implements a **ReAct (Reasoning + Acting) loop** for RAG queries. Instead of a single retrieval, the system iteratively:\n\n1. **Action**: Query RAG with the current search query\n2. **Thought**: LLM evaluates whether the retrieved answer is sufficient\n3. **Observation**: If insufficient, LLM generates a refined follow-up query\n4. **Repeat** until the answer is complete or max iterations reached\n5. **Synthesize**: All accumulated chunks are combined into a comprehensive final answer\n\n### ReAct Loop Flow\n\n```\nOriginal Question\n  -> Iteration 1:\n       ACTION:      RAG query (original question)\n       OBSERVATION: Retrieved chunks + synthesized answer\n       THOUGHT:     LLM evaluates: \"Is this sufficient?\"\n         -> Yes: Break, synthesize final answer\n         -> No:  Generate follow-up query\n  -> Iteration 2:\n       ACTION:      RAG query (refined follow-up query)\n       OBSERVATION: New chunks accumulated\n       THOUGHT:     LLM evaluates again (with memory of previous iterations)\n         -> ...\n  -> Final Synthesis:\n       All accumulated chunks -> LLM -> Comprehensive answer\n```\n\n### Prerequisites\n\n1. Both servers must be running (`python tools_server.py` then `python run_backend.py`)\n2. At least one RAG collection must exist with uploaded documents\n3. `RAG_DEFAULT_COLLECTION` in `config.py` must match the target collection name"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "class LLMApiClient:\n",
    "    \"\"\"Unified client for the LLM API server.\"\"\"\n",
    "\n",
    "    def __init__(self, base_url: str, timeout: float = 6000.0):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.token = None\n",
    "        self.timeout = httpx.Timeout(50.0, read=timeout, write=timeout, pool=timeout)\n",
    "\n",
    "    def _headers(self):\n",
    "        return {\"Authorization\": f\"Bearer {self.token}\"} if self.token else {}\n",
    "\n",
    "    # ---- Auth ----\n",
    "\n",
    "    def login(self, username: str, password: str):\n",
    "        r = httpx.post(\n",
    "            f\"{self.base_url}/api/auth/login\",\n",
    "            json={\"username\": username, \"password\": password},\n",
    "            timeout=10.0,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        self.token = r.json()[\"access_token\"]\n",
    "        return r.json()\n",
    "\n",
    "    def list_models(self):\n",
    "        r = httpx.get(f\"{self.base_url}/v1/models\", headers=self._headers(), timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    # ---- Chat (auto agent) ----\n",
    "\n",
    "    def chat_new(self, model: str, user_message: str, agent_type: str = \"auto\"):\n",
    "        \"\"\"Start a new chat session. Returns (response_text, session_id).\"\"\"\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"messages\": json.dumps(messages),\n",
    "            \"agent_type\": agent_type,\n",
    "        }\n",
    "        r = httpx.post(\n",
    "            f\"{self.base_url}/v1/chat/completions\",\n",
    "            data=data,\n",
    "            headers=self._headers(),\n",
    "            timeout=self.timeout,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        result = r.json()\n",
    "        return result[\"choices\"][0][\"message\"][\"content\"], result[\"x_session_id\"]\n",
    "\n",
    "    def chat_continue(self, model: str, session_id: str, user_message: str, agent_type: str = \"auto\"):\n",
    "        \"\"\"Continue an existing session. Returns (response_text, session_id).\"\"\"\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"messages\": json.dumps(messages),\n",
    "            \"session_id\": session_id,\n",
    "            \"agent_type\": agent_type,\n",
    "        }\n",
    "        r = httpx.post(\n",
    "            f\"{self.base_url}/v1/chat/completions\",\n",
    "            data=data,\n",
    "            headers=self._headers(),\n",
    "            timeout=self.timeout,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        result = r.json()\n",
    "        return result[\"choices\"][0][\"message\"][\"content\"], result[\"x_session_id\"]\n",
    "\n",
    "    # ---- RAG management (direct tools-server calls) ----\n",
    "\n",
    "    def rag_list_collections(self, tools_base: str):\n",
    "        \"\"\"List all RAG collections for the authenticated user.\"\"\"\n",
    "        r = httpx.get(\n",
    "            f\"{tools_base}/api/tools/rag/collections\",\n",
    "            headers=self._headers(),\n",
    "            timeout=10.0,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def rag_list_documents(self, tools_base: str, collection_name: str):\n",
    "        \"\"\"List documents in a RAG collection.\"\"\"\n",
    "        r = httpx.get(\n",
    "            f\"{tools_base}/api/tools/rag/collections/{collection_name}/documents\",\n",
    "            headers=self._headers(),\n",
    "            timeout=10.0,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def rag_query_direct(self, tools_base: str, query: str, collection_name: str, max_results: int = 5):\n",
    "        \"\"\"Query RAG directly via the tools server (bypasses the agent).\"\"\"\n",
    "        r = httpx.post(\n",
    "            f\"{tools_base}/api/tools/rag/query\",\n",
    "            headers=self._headers(),\n",
    "            json={\n",
    "                \"query\": query,\n",
    "                \"collection_name\": collection_name,\n",
    "                \"max_results\": max_results,\n",
    "            },\n",
    "            timeout=self.timeout,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def rag_upload_document(self, tools_base: str, collection_name: str, file_path: str):\n",
    "        \"\"\"Upload a local document to a RAG collection.\"\"\"\n",
    "        from pathlib import Path\n",
    "        \n",
    "        file_path = Path(file_path)\n",
    "        if not file_path.exists():\n",
    "            raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "        \n",
    "        with open(file_path, \"rb\") as f:\n",
    "            files = {\"file\": (file_path.name, f, \"application/octet-stream\")}\n",
    "            data = {\"collection_name\": collection_name}\n",
    "            \n",
    "            r = httpx.post(\n",
    "                f\"{tools_base}/api/tools/rag/upload\",\n",
    "                headers=self._headers(),\n",
    "                files=files,\n",
    "                data=data,\n",
    "                timeout=self.timeout,\n",
    "            )\n",
    "        \n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def rag_create_collection(self, tools_base: str, collection_name: str):\n",
    "        \"\"\"Create a new RAG collection.\"\"\"\n",
    "        r = httpx.post(\n",
    "            f\"{tools_base}/api/tools/rag/collections\",\n",
    "            headers=self._headers(),\n",
    "            json={\"collection_name\": collection_name},\n",
    "            timeout=10.0,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def rag_delete_collection(self, tools_base: str, collection_name: str):\n",
    "        \"\"\"Delete a RAG collection.\"\"\"\n",
    "        r = httpx.delete(\n",
    "            f\"{tools_base}/api/tools/rag/collections/{collection_name}\",\n",
    "            headers=self._headers(),\n",
    "            timeout=10.0,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def rag_delete_document(self, tools_base: str, collection_name: str, document_id: str):\n",
    "        \"\"\"Delete a specific document from a collection.\"\"\"\n",
    "        r = httpx.delete(\n",
    "            f\"{tools_base}/api/tools/rag/collections/{collection_name}/documents/{document_id}\",\n",
    "            headers=self._headers(),\n",
    "            timeout=10.0,\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# Configuration  (adjust to your environment)\n",
    "# -------------------------------------------------------------------\n",
    "API_BASE_URL   = \"http://localhost:10007\"   # Main API server\n",
    "TOOLS_BASE_URL = \"http://localhost:10006\"   # Tools API server\n",
    "USERNAME = \"admin\"\n",
    "PASSWORD = \"administrator\"\n",
    "\n",
    "client = LLMApiClient(API_BASE_URL, timeout=600.0)\n",
    "print(\"\\u2713 Client initialized\")\n",
    "print(f\"  Main server : {API_BASE_URL}\")\n",
    "print(f\"  Tools server: {TOOLS_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Authenticate and Discover Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.login(USERNAME, PASSWORD)\n",
    "models = client.list_models()\n",
    "MODEL = models[\"data\"][0][\"id\"]\n",
    "\n",
    "print(f\"\\u2713 Logged in as: {USERNAME}\")\n",
    "print(f\"\\u2713 Using model : {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Local Documents to RAG (Optional)\n",
    "\n",
    "If you want to add your own documents to RAG, use this section. Skip to Step 3 if you already have documents uploaded.\n",
    "\n",
    "### Supported File Formats\n",
    "\n",
    "- **Text**: `.txt`, `.md`\n",
    "- **Documents**: `.pdf`, `.docx`\n",
    "- **Data**: `.json`, `.csv`, `.xlsx`, `.xls`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new RAG collection and upload documents\n",
    "from pathlib import Path\n",
    "\n",
    "# Step 1: Create collection\n",
    "collection_name = \"default\"  # Change this to your desired collection name\n",
    "\n",
    "try:\n",
    "    print(f\"Creating collection '{collection_name}'...\")\n",
    "    result = client.rag_create_collection(TOOLS_BASE_URL, collection_name)\n",
    "    \n",
    "    if result.get(\"success\"):\n",
    "        print(f\"âœ“ Collection created successfully!\")\n",
    "        print(f\"  Collection name: {collection_name}\\n\")\n",
    "    else:\n",
    "        print(f\"âœ— Failed to create collection: {result.get('error')}\\n\")\n",
    "except Exception as e:\n",
    "    print(f\"âœ— Error creating collection: {e}\\n\")\n",
    "\n",
    "# Step 2: Upload your PDF files\n",
    "# Replace with your actual PDF file paths\n",
    "custom_pdf_files = [\n",
    "    \"./USB 3.2 Revision 1.1.pdf\",\n",
    "    \"./usb_20.pdf\"\n",
    "]\n",
    "\n",
    "print(f\"Uploading {len(custom_pdf_files)} documents...\\n\")\n",
    "\n",
    "for pdf_file in custom_pdf_files:\n",
    "    # Check if file exists\n",
    "    if not Path(pdf_file).exists():\n",
    "        print(f\"âš ï¸  File not found: {pdf_file}\\n\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"ğŸ“¤ Uploading: {pdf_file}\")\n",
    "    \n",
    "    try:\n",
    "        result = client.rag_upload_document(TOOLS_BASE_URL, collection_name, pdf_file)\n",
    "        \n",
    "        if result.get('success'):\n",
    "            print(f\"  âœ“ Success! Chunks created: {result.get('chunks_created')}\")\n",
    "            print(f\"  Total chunks in collection: {result.get('total_chunks')}\\n\")\n",
    "        else:\n",
    "            print(f\"  âœ— Failed: {result.get('error')}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âœ— Error: {str(e)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Browse Existing RAG Collections\n",
    "\n",
    "Let's see which collections and documents are available after any uploads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collections_result = client.rag_list_collections(TOOLS_BASE_URL)\n",
    "\n",
    "if collections_result.get(\"success\"):\n",
    "    collections = collections_result[\"collections\"]\n",
    "    print(f\"Found {len(collections)} collection(s):\\n\")\n",
    "    for coll in collections:\n",
    "        print(f\"  Collection : {coll['name']}\")\n",
    "        print(f\"  Documents  : {coll['documents']}\")\n",
    "        print(f\"  Chunks     : {coll['chunks']}\")\n",
    "        print(f\"  Created    : {coll['created_at']}\")\n",
    "        print()\n",
    "else:\n",
    "    print(\"ERROR: Could not list collections.\")\n",
    "    print(collections_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 4: Inspect Documents in a Collection\n\nPick the collection you want to query with the RAG ReAct loop.  \nSet `COLLECTION_NAME` below to match one of the collections listed above."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Set this to the collection you want to use ===\n",
    "COLLECTION_NAME = \"default\"\n",
    "\n",
    "docs_result = client.rag_list_documents(TOOLS_BASE_URL, COLLECTION_NAME)\n",
    "\n",
    "if docs_result.get(\"success\"):\n",
    "    print(f\"Collection   : {docs_result['collection_name']}\")\n",
    "    print(f\"Total docs   : {docs_result['total_documents']}\")\n",
    "    print(f\"Total chunks : {docs_result['total_chunks']}\")\n",
    "    print(f\"\\nDocuments:\")\n",
    "    for doc in docs_result[\"documents\"]:\n",
    "        print(f\"  - {doc['name']}  ({doc['chunks']} chunks, uploaded {doc['uploaded_at']})\")\n",
    "else:\n",
    "    print(f\"ERROR: Could not list documents in '{COLLECTION_NAME}'.\")\n",
    "    print(docs_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 5: Verify RAG_DEFAULT_COLLECTION\n\nThe RAG tool uses `RAG_DEFAULT_COLLECTION` from `config.py` to decide which collection to search.  \nMake sure the value in `config.py` matches the collection you want to query **before starting the servers**.\n\n```python\n# In config.py:\nRAG_DEFAULT_COLLECTION = \"default\"  # <-- must match your target collection\n```\n\nIf you need to change it, edit `config.py` and restart both servers."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sanity check: read the current config value\n",
    "import importlib, sys\n",
    "\n",
    "# Add project root so we can import config\n",
    "sys.path.insert(0, \"..\")\n",
    "import config as cfg\n",
    "importlib.reload(cfg)\n",
    "\n",
    "print(f\"RAG_DEFAULT_COLLECTION = \\\"{cfg.RAG_DEFAULT_COLLECTION}\\\"\")\n",
    "print(f\"Target collection      = \\\"{COLLECTION_NAME}\\\"\")\n",
    "\n",
    "if cfg.RAG_DEFAULT_COLLECTION == COLLECTION_NAME:\n",
    "    print(\"\\n\\u2713 Config matches. The auto agent will query the correct collection.\")\n",
    "else:\n",
    "    print(f\"\\n\\u2717 MISMATCH! Edit config.py to set RAG_DEFAULT_COLLECTION = \\\"{COLLECTION_NAME}\\\"\")\n",
    "    print(\"  Then restart both servers.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 6: RAG ReAct Loop\n\nThe `rag_react_query()` function implements a ReAct loop around direct RAG queries:\n\n- Each iteration queries RAG, then asks the LLM to evaluate if the answer is sufficient\n- The evaluation LLM uses `chat_continue` to maintain session context across iterations (it remembers what it already assessed)\n- All retrieved chunks are accumulated and deduplicated across iterations\n- When sufficient (or max iterations reached), all chunks are synthesized into a final comprehensive answer\n- **Verbose printouts** show each step: Action, Observation, Thought"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import time\nimport hashlib\nimport re\nfrom IPython.display import display, Markdown\n\n\nEVALUATION_PROMPT_TEMPLATE = \"\"\"You are evaluating whether a RAG (Retrieval Augmented Generation) answer sufficiently addresses the user's original question.\n\n## Original Question\n{original_query}\n\n## Current RAG Query\n{current_query}\n\n## RAG Answer\n{rag_answer}\n\n## Retrieved Sources\n{sources_summary}\n\n## Previously Gathered Information\n{accumulated_summary}\n\n## Instructions\nEvaluate whether the information gathered so far (including this iteration) adequately answers the original question with specific, accurate, and detailed information.\n\nConsider:\n1. Does the answer contain concrete data (numbers, specs, definitions) rather than vague generalizations?\n2. Are there obvious gaps or missing aspects of the question that haven't been addressed?\n3. Would a different search query likely retrieve additional useful information?\n\nRespond in EXACTLY this format (no extra text before or after):\nsufficient: true OR sufficient: false\nreasoning: <1-2 sentences explaining your judgment>\nfollow_up_query: <a refined search query to fill gaps, or \"none\" if sufficient>\"\"\"\n\n\nSYNTHESIS_PROMPT_TEMPLATE = \"\"\"Based on the following retrieved document chunks, provide a comprehensive and detailed answer to the user's question.\n\n## User's Question\n{original_query}\n\n## Retrieved Document Chunks\n{all_chunks_formatted}\n\n## Instructions\n- Synthesize ALL the retrieved chunks into a single, well-organized answer\n- Include specific data, numbers, and technical details from the documents\n- If chunks contain contradictory information, note the discrepancy\n- Structure your answer clearly with sections/bullet points as appropriate\n- Only use information from the provided chunks â€” do not add external knowledge\n- If the chunks don't fully answer the question, clearly state what information is missing\"\"\"\n\n\ndef rag_react_query(query, collection_name, model, max_iterations=3, max_results=5):\n    \"\"\"\n    ReAct loop for RAG queries.\n    \n    Iteratively queries RAG, evaluates sufficiency via LLM, and refines\n    the search query until the answer is comprehensive.\n    \n    Args:\n        query: Original user question\n        collection_name: RAG collection to search\n        model: LLM model name for evaluation/synthesis\n        max_iterations: Maximum number of retrieval iterations (default 3)\n        max_results: Number of chunks per RAG query (default 5)\n    \n    Returns:\n        (final_answer, history) tuple\n    \"\"\"\n    all_chunks = []\n    seen_hashes = set()\n    history = []\n    current_query = query\n    eval_session_id = None\n    total_start = time.time()\n\n    print(f\"{'=' * 80}\")\n    print(f\"  RAG ReAct Loop\")\n    print(f\"  Original Question: {query}\")\n    print(f\"  Collection: {collection_name} | Max Iterations: {max_iterations}\")\n    print(f\"{'=' * 80}\\n\")\n\n    for iteration in range(1, max_iterations + 1):\n        iter_start = time.time()\n        print(f\"--- Iteration {iteration}/{max_iterations} {'---' * 20}\")\n\n        # ========== ACTION: RAG Retrieval ==========\n        print(f\"\\n  [ACTION] Querying RAG...\")\n        print(f\"    Query: \\\"{current_query}\\\"\")\n\n        rag_start = time.time()\n        result = client.rag_query_direct(\n            TOOLS_BASE_URL,\n            query=current_query,\n            collection_name=collection_name,\n            max_results=max_results,\n        )\n        rag_time = time.time() - rag_start\n\n        if not result.get(\"success\"):\n            print(f\"    ERROR: {result.get('error')}\")\n            history.append({\n                \"iteration\": iteration,\n                \"query\": current_query,\n                \"error\": result.get(\"error\"),\n            })\n            break\n\n        rag_answer = result[\"answer\"]\n        data = result.get(\"data\", {})\n        documents = data.get(\"documents\", [])\n\n        print(f\"    Retrieved: {len(documents)} chunks in {rag_time:.2f}s\")\n\n        # ========== OBSERVATION: Show retrieved results ==========\n        print(f\"\\n  [OBSERVATION] Retrieved chunks:\")\n        new_chunks_count = 0\n        sources_lines = []\n        for i, doc in enumerate(documents, 1):\n            score = doc.get(\"score\", 0)\n            source_line = f\"    [{i}] {doc['document']} chunk {doc['chunk_index']} (score: {score:.3f})\"\n            print(source_line)\n            sources_lines.append(source_line)\n\n            # Deduplicate by content hash\n            chunk_hash = hashlib.md5(doc[\"chunk\"].encode()).hexdigest()\n            if chunk_hash not in seen_hashes:\n                seen_hashes.add(chunk_hash)\n                all_chunks.append(doc)\n                new_chunks_count += 1\n\n        print(f\"\\n    New unique chunks: {new_chunks_count} | Total accumulated: {len(all_chunks)}\")\n        print(f\"\\n  [RAG ANSWER] (truncated to 300 chars):\")\n        print(f\"    {rag_answer[:300]}{'...' if len(rag_answer) > 300 else ''}\")\n\n        # ========== THOUGHT: LLM evaluates sufficiency ==========\n        print(f\"\\n  [THOUGHT] Evaluating answer sufficiency via LLM...\")\n\n        accumulated_summary = \"None (first iteration)\" if iteration == 1 else \\\n            f\"{len(all_chunks)} total chunks accumulated from {iteration - 1} previous queries\"\n\n        eval_prompt = EVALUATION_PROMPT_TEMPLATE.format(\n            original_query=query,\n            current_query=current_query,\n            rag_answer=rag_answer,\n            sources_summary=\"\\n\".join(sources_lines),\n            accumulated_summary=accumulated_summary,\n        )\n\n        eval_start = time.time()\n        if eval_session_id is None:\n            eval_response, eval_session_id = client.chat_new(\n                model=model,\n                user_message=eval_prompt,\n                agent_type=\"chat\",\n            )\n        else:\n            eval_response, eval_session_id = client.chat_continue(\n                model=model,\n                session_id=eval_session_id,\n                user_message=eval_prompt,\n                agent_type=\"chat\",\n            )\n        eval_time = time.time() - eval_start\n\n        # Parse evaluation response\n        is_sufficient = False\n        reasoning = \"\"\n        follow_up_query = \"\"\n\n        for line in eval_response.strip().split(\"\\n\"):\n            line_lower = line.strip().lower()\n            if line_lower.startswith(\"sufficient:\"):\n                is_sufficient = \"true\" in line_lower\n            elif line_lower.startswith(\"reasoning:\"):\n                reasoning = line.strip()[len(\"reasoning:\"):].strip()\n            elif line_lower.startswith(\"follow_up_query:\"):\n                follow_up_query = line.strip()[len(\"follow_up_query:\"):].strip()\n\n        iter_time = time.time() - iter_start\n\n        print(f\"    Sufficient: {'YES' if is_sufficient else 'NO'}\")\n        print(f\"    Reasoning: {reasoning}\")\n        if not is_sufficient and follow_up_query and follow_up_query.lower() != \"none\":\n            print(f\"    Follow-up query: \\\"{follow_up_query}\\\"\")\n        print(f\"    (eval LLM: {eval_time:.2f}s | iteration total: {iter_time:.2f}s)\")\n\n        history.append({\n            \"iteration\": iteration,\n            \"query\": current_query,\n            \"rag_answer\": rag_answer,\n            \"chunks_retrieved\": len(documents),\n            \"new_unique_chunks\": new_chunks_count,\n            \"sufficient\": is_sufficient,\n            \"reasoning\": reasoning,\n            \"follow_up_query\": follow_up_query,\n            \"rag_time\": rag_time,\n            \"eval_time\": eval_time,\n        })\n\n        if is_sufficient:\n            print(f\"\\n  >>> Answer deemed SUFFICIENT at iteration {iteration}. Proceeding to synthesis.\")\n            break\n\n        if follow_up_query and follow_up_query.lower() != \"none\":\n            current_query = follow_up_query\n        else:\n            print(f\"\\n  >>> No follow-up query generated. Stopping loop.\")\n            break\n\n        print()\n\n    # ========== FINAL SYNTHESIS ==========\n    print(f\"\\n{'=' * 80}\")\n    print(f\"  [SYNTHESIS] Generating final answer from {len(all_chunks)} accumulated chunks...\")\n    print(f\"{'=' * 80}\")\n\n    chunks_formatted = \"\\n\\n\".join([\n        f\"[Chunk {i+1}] Source: {doc['document']}, Chunk {doc['chunk_index']} \"\n        f\"(Score: {doc.get('score', 0):.3f}):\\n{doc['chunk']}\"\n        for i, doc in enumerate(all_chunks)\n    ])\n\n    synthesis_prompt = SYNTHESIS_PROMPT_TEMPLATE.format(\n        original_query=query,\n        all_chunks_formatted=chunks_formatted,\n    )\n\n    synth_start = time.time()\n    final_answer, _ = client.chat_new(\n        model=model,\n        user_message=synthesis_prompt,\n        agent_type=\"chat\",\n    )\n    synth_time = time.time() - synth_start\n    total_time = time.time() - total_start\n\n    # Display final answer\n    print(f\"\\n  Synthesis LLM time: {synth_time:.2f}s\")\n    print(f\"  Total elapsed: {total_time:.2f}s\")\n    print(f\"  Iterations used: {len(history)}/{max_iterations}\")\n    print(f\"  Total unique chunks: {len(all_chunks)}\")\n    print(f\"\\n{'=' * 80}\\n\")\n\n    display(Markdown(f\"### Final Answer\\n\\n{final_answer}\"))\n\n    # Display iteration summary\n    summary_lines = [\"### ReAct Loop Summary\\n\", \"| Iter | Query | Chunks | New | Sufficient | Reasoning |\",\n                     \"|------|-------|--------|-----|------------|-----------|\"]\n    for h in history:\n        q = h['query'][:40] + \"...\" if len(h['query']) > 40 else h['query']\n        summary_lines.append(\n            f\"| {h['iteration']} | {q} | {h.get('chunks_retrieved', 0)} | \"\n            f\"{h.get('new_unique_chunks', 0)} | {'Yes' if h.get('sufficient') else 'No'} | \"\n            f\"{h.get('reasoning', '')[:60]} |\"\n        )\n    summary_lines.append(f\"\\n**Total time:** {total_time:.2f}s | **Total chunks:** {len(all_chunks)}\")\n    display(Markdown(\"\\n\".join(summary_lines)))\n\n    return final_answer, history\n\n\nprint(\"ReAct RAG loop utility loaded\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: C-PHY Insertion Loss at 3.9Gsps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_1 = \"C-PHYê°€ 3.9Gspsë¡œ ë™ì‘í•  ë•Œ Insertion Loss ìŠ¤í™ì„ ì•Œë ¤ì¤˜\"\nrag_react_query(query_1, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: MIPI C-PHY SKEW Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_2 = \"MIPI C-PHYì—ì„œ SKEW Errorì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\nrag_react_query(query_2, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: MIPI M-PHY v6.0 FOM and EOM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_3 = \"MIPI M-PHY v6.0ì˜ FOMê³¼ EOMì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜. ê°ê°ì— ëŒ€í•´ ë¹„êµí•´ì£¼ê³ , Spec.ì—ì„œëŠ” Mandatoryì‚¬í•­ì¸ì§€, Optionì‚¬í•­ì¸ì§€ í™•ì¸í•´ì¤˜\"\nrag_react_query(query_3, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: USB3.2 LTSSM and RX.Detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_4 = \"USB3.2ì˜ LTSSMì— ëŒ€í•´ì„œ ìì„¸íˆ ì„¤ëª…í•´ì£¼ê³ , íŠ¹íˆ RX.Detectì— ëŒ€í•´ì„œ ìì„¸íˆ ì„¤ëª…í•´ì¤˜\"\nrag_react_query(query_4, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5: PCIe AER (Advanced Error Reporting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_5 = \"PCIe AERì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³ , ëŒ€í‘œì ì¸ Error ë“¤ì— ëŒ€í•´ì„œ ë¹„êµ ì„¤ëª…í•´ì¤˜\"\nrag_react_query(query_5, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6: USB3.2 Gen1/Gen2 Transmitter Eye Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_6 = \"USB3.2ì˜ Gen1(5GT/s), Gen2(10GT/s)ì˜ Transmitter eye mask ê·œê²©ì— ëŒ€í•´ì„œ ì¸¡ì • ìœ„ì¹˜ì™€ Eye Height spec.(Minimum, Maximum)ì— ëŒ€í•´ì„œ ë¹„êµ ì„¤ëª…í•´ì¤˜\"\nrag_react_query(query_6, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7: DisplayPort Link Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_7 = \"DP Sourceì™€ Sinkê°„ Link training ì ˆì°¨ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³ , Clock Recovery, Channel equalization, Symbol Lockì„ ìˆ˜í–‰í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜\"\nrag_react_query(query_7, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8: USB2.0 High-Speed Disconnect Level (VHSDSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_8 = \"USB2.0ì˜ high-speed Disconnect level(VHSDSC)ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³ , ìµœì´ˆ USB2.0 spec.ëŒ€ë¹„ USB 2.0 DCR ECNì— ì˜í•´ ë³€ê²½ëœ ì‚¬í•­ì— ëŒ€í•´ ì•Œë ¤ì¤˜\"\nrag_react_query(query_8, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 9: USB4.0, USB3.2, USB2.0 Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_9 = \"USB4.0, USB3.2, USB2.0 ê°ê°ì˜ Spec.ì— ëŒ€í•´ì„œ ì‹ í˜¸ë¥¼ ì „ì†¡í•˜ëŠ” ì „ì†¡ë°©ì‹ê³¼ ìµœëŒ€ ë™ì‘ì†ë„ì™€ ë¬¼ë¦¬ì ì¸ ë°°ì„ ì˜ ì°¨ì´ì ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì¤˜\"\nrag_react_query(query_9, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 10: UFS, Unipro AFCx Frame Transmission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_10 = \"UFS, Uniproì˜ AFCx Frame Transmissionì— ëŒ€í•œ ì„¤ëª…ì„ í•´ì£¼ê³ , FCx_PROTECTION_TIMER or TCx_REPLAY_TIMERì— ëŒ€í•´ì„œë„ ì„¤ëª…í•´ì¤˜\"\nrag_react_query(query_10, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 11: UFS, MIPI MPHY, Unipro Link Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_11 = \"UFSëŠ” MIPI MPHY, Uniproë¡œ ì´ë£¨ì–´ì§€ëŠ”ë° ê°ê°ì— ëŒ€í•´ì„œ ì„¤ëª…ì„ í•´ì£¼ê³ , Link initialization processì— ëŒ€í•´ì„œ í™•ì¸í•´ì¤˜\"\nrag_react_query(query_11, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 12: DisplayPort 1.4 Voltage Swing and Pre-emphasis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_12 = \"DP1.4 spec.ì—ì„œ ì •ì˜í•˜ëŠ” Voltage Swing and Pre-emphasisì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì£¼ê³ , Voltage swing levelê³¼ TX Emphasis Levelì´ 0/1/2/3ìœ¼ë¡œ ì„¤ì •ë˜ëŠ” ì´ìœ ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜\"\nrag_react_query(query_12, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 13: MIPI C-PHY Crosstalk Spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_13 = \"MIPI C-PHY crosstalk specì€?\"\nrag_react_query(query_13, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 14: Interface Impedance Guide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_14 = \"ì¸í„°í˜ì´ìŠ¤ë³„ ì„í”¼ë˜ìŠ¤ ê°€ì´ë“œë¥¼ ì•Œë ¤ì¤˜\"\nrag_react_query(query_14, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 15: MIPI D-PHY Initial vs Periodic Skew Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_15 = \"MIPI D-phyì—ì„œ Initial Skew calê³¼ Periodic Skew calì˜ ì°¨ì´ì— ëŒ€í•´ì„œ ì„¤ëª…í•´ì¤˜\"\nrag_react_query(query_15, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 16: USB3.2 Gen2 Electrical Compliance Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_16 = \"USB3.2 Gen2 ë™ì‘ ì‹œì˜ Electrical Compliance Test í•­ëª©ì— ëŒ€í•´ì„œ ì•Œë ¤ì¤˜\"\nrag_react_query(query_16, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 17: eUSB Repeater Mode eSE1 Signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_17 = \"eUSBì˜ Repeater modeì—ì„œ eSE1 ì‹ í˜¸ê°€ ë°œìƒí•˜ëŠ” ê²½ìš°ì— ëŒ€í•´ ì„¤ëª…í•´ ì£¼ì„¸ìš”\"\nrag_react_query(query_17, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 18: USB vs eUSB FS Signaling Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_18 = \"USBì™€ eUSBì˜ FS signaling ì°¨ì´ë¥¼ ì„¤ëª…í•´ ì£¼ì„¸ìš”\"\nrag_react_query(query_18, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 19: USB3.0 Voltage Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_19 = \"USB3.0 ì „ì•• ë ˆë²¨ì€ ì–´ë–»ê²Œë˜ì§€?\"\nrag_react_query(query_19, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 20: USB2.0 EQ Impact on Design Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_20 = \"USB2.0ì—ì„œ EQì„ ì‚¬ìš©í•œ ê²½ìš°ì™€ ì‚¬ìš©í•˜ì§€ ì•Šì€ ê²½ìš°ì— ì„¤ê³„ ê¸¸ì´ì˜ ì°¨ì´ëŠ” ì–¼ë§ˆë‚˜ ë ê¹Œ?\"\nrag_react_query(query_20, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 21: USB3.2 Gen2x2 8b/10b Encoding Maximum Speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "query_21 = \"USB3.2 Gen2x2 ì—ì„œ 8b/10b ì¸ì½”ë”© ë°©ì‹ì„ ì‚¬ìš©í• ë•Œ ìµœëŒ€ ì „ì†¡ ì†ë„ëŠ” ì–¼ë§ˆê°€ ë ê¹Œ?\"\nrag_react_query(query_21, COLLECTION_NAME, MODEL)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary\n\nThis notebook demonstrated:\n\n1. **Uploading local documents to RAG** â€” Add your own documents (PDF, TXT, MD, DOCX, CSV, etc.) to RAG collections\n2. **Browsing existing RAG collections** â€” List collections and inspect their documents\n3. **Config verification** â€” Ensure `RAG_DEFAULT_COLLECTION` points to the right collection\n4. **RAG ReAct Loop** â€” Iterative retrieval with LLM-based sufficiency evaluation\n5. **Accumulated retrieval** â€” Multiple RAG queries build up a comprehensive chunk set, deduplicated by content\n6. **LLM evaluation with session memory** â€” `chat_continue` allows the evaluator LLM to remember previous assessments across iterations\n7. **Final synthesis** â€” All accumulated chunks are synthesized into a comprehensive answer\n8. **Collection management** â€” Create/delete collections and remove specific documents\n\n### ReAct Loop Flow\n\n```\nrag_react_query(question)\n  â”œâ”€â”€ Iteration 1: RAG query (original) â†’ LLM evaluates â†’ sufficient? \n  â”‚     â”œâ”€â”€ Yes â†’ Synthesize from all chunks â†’ Done\n  â”‚     â””â”€â”€ No  â†’ Generate follow-up query\n  â”œâ”€â”€ Iteration 2: RAG query (refined) â†’ LLM evaluates (with session memory) â†’ sufficient?\n  â”‚     â””â”€â”€ ...\n  â””â”€â”€ Final: Synthesize all accumulated unique chunks â†’ Comprehensive answer\n```\n\n### API Endpoints Used\n\n| Endpoint | Purpose |\n|----------|--------|\n| `POST /api/auth/login` | Authentication |\n| `GET /v1/models` | Discover available models |\n| `POST /api/tools/rag/upload` | Upload document to RAG collection |\n| `POST /api/tools/rag/collections` | Create new collection |\n| `GET /api/tools/rag/collections` | List existing collections |\n| `GET /api/tools/rag/collections/{name}/documents` | List documents in a collection |\n| `DELETE /api/tools/rag/collections/{name}/documents/{id}` | Delete specific document |\n| `DELETE /api/tools/rag/collections/{name}` | Delete entire collection |\n| `POST /api/tools/rag/query` | Direct RAG query (tools server) |\n| `POST /v1/chat/completions` | LLM evaluation & synthesis (main server, chat agent) |"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 7: Collection Management (Optional)\n\nYou can also create new collections, delete collections, or delete specific documents."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new collection\n",
    "# Uncomment to create\n",
    "\n",
    "# new_collection_name = \"my_new_collection\"\n",
    "# try:\n",
    "#     result = client.rag_create_collection(TOOLS_BASE_URL, new_collection_name)\n",
    "#     if result.get(\"success\"):\n",
    "#         print(f\"âœ“ Collection '{new_collection_name}' created successfully\")\n",
    "#     else:\n",
    "#         print(f\"âœ— Failed: {result.get('error')}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"âœ— Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a document from a collection\n",
    "# First, list documents to get the document ID, then uncomment to delete\n",
    "\n",
    "# collection_name = \"default\"\n",
    "# document_id = \"abc123...\"  # Get this from list_documents result\n",
    "\n",
    "# try:\n",
    "#     result = client.rag_delete_document(TOOLS_BASE_URL, collection_name, document_id)\n",
    "#     if result.get(\"success\"):\n",
    "#         print(f\"âœ“ Document deleted successfully\")\n",
    "#         print(f\"  Deleted: {result.get('deleted_document')}\")\n",
    "#         print(f\"  Remaining documents: {result.get('remaining_documents')}\")\n",
    "#     else:\n",
    "#         print(f\"âœ— Failed: {result.get('error')}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"âœ— Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete an entire collection (use with caution!)\n",
    "# Uncomment to delete\n",
    "\n",
    "# collection_to_delete = \"test_collection\"\n",
    "# try:\n",
    "#     result = client.rag_delete_collection(TOOLS_BASE_URL, collection_to_delete)\n",
    "#     if result.get(\"success\"):\n",
    "#         print(f\"âœ“ Collection '{collection_to_delete}' deleted successfully\")\n",
    "#     else:\n",
    "#         print(f\"âœ— Failed: {result.get('error')}\")\n",
    "# except Exception as e:\n",
    "#     print(f\"âœ— Error: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}