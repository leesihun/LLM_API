{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "694cf768",
   "metadata": {},
   "source": "# Hyperparameter tuning script for ML models"
  },
  {
   "cell_type": "markdown",
   "id": "bde86e6a",
   "metadata": {},
   "source": [
    "### Example scripts designed by SiHun Lee, Ph. D using LLM API and Meshgraphnets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a1540",
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "from IPython.display import display, Latex\n",
    "\n",
    "# Build Universal LLM API Client\n",
    "class LLMApiClient:\n",
    "    def __init__(self, base_url: str, timeout: float = 3600000000.0):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.token = None\n",
    "        self.timeout = httpx.Timeout(50.0, read=timeout, write=timeout, pool=timeout)\n",
    "\n",
    "    def _headers(self):\n",
    "        return {\"Authorization\": f\"Bearer {self.token}\"} if self.token else {}\n",
    "\n",
    "    def login(self, username: str, password: str):\n",
    "        r = httpx.post(f\"{self.base_url}/api/auth/login\", \n",
    "                      json={\"username\": username, \"password\": password}, timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        self.token = r.json()[\"access_token\"]\n",
    "        return r.json()\n",
    "\n",
    "    def list_models(self):\n",
    "        r = httpx.get(f\"{self.base_url}/v1/models\", headers=self._headers(), timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def chat_new(self, model: str, user_message: str, agent_type: str = \"auto\", files: list = None):\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        data = {\"model\": model, \"messages\": json.dumps(messages), \"agent_type\": agent_type}\n",
    "        \n",
    "        files_to_upload = []\n",
    "        if files:\n",
    "            for file_path in files:\n",
    "                f = open(file_path, \"rb\")\n",
    "                files_to_upload.append((\"files\", (Path(file_path).name, f)))\n",
    "        \n",
    "        try:\n",
    "            r = httpx.post(f\"{self.base_url}/v1/chat/completions\", data=data,\n",
    "                          files=files_to_upload if files_to_upload else None,\n",
    "                          headers=self._headers(), timeout=self.timeout)\n",
    "            r.raise_for_status()\n",
    "            result = r.json()\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"], result[\"x_session_id\"]\n",
    "        finally:\n",
    "            for _, (_, f) in files_to_upload:\n",
    "                f.close()\n",
    "\n",
    "    def chat_continue(self, model: str, session_id: str, user_message: str, \n",
    "                     agent_type: str = \"auto\", files: list = None):\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        data = {\"model\": model, \"messages\": json.dumps(messages), \n",
    "                \"session_id\": session_id, \"agent_type\": agent_type}\n",
    "        \n",
    "        files_to_upload = []\n",
    "        if files:\n",
    "            for file_path in files:\n",
    "                f = open(file_path, \"rb\")\n",
    "                files_to_upload.append((\"files\", (Path(file_path).name, f)))\n",
    "        \n",
    "        try:\n",
    "            r = httpx.post(f\"{self.base_url}/v1/chat/completions\", data=data,\n",
    "                          files=files_to_upload if files_to_upload else None,\n",
    "                          headers=self._headers(), timeout=self.timeout)\n",
    "            r.raise_for_status()\n",
    "            result = r.json()\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"], result[\"x_session_id\"]\n",
    "        finally:\n",
    "            for _, (_, f) in files_to_upload:\n",
    "                f.close()\n",
    "\n",
    "    def get_session_artifacts(self, session_id: str):\n",
    "        \"\"\"Get list of files generated during the session\"\"\"\n",
    "        r = httpx.get(f\"{self.base_url}/api/chat/sessions/{session_id}/artifacts\",\n",
    "                     headers=self._headers(), timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def download_artifact(self, session_id: str, filename: str, save_to: str = None):\n",
    "        \"\"\"\n",
    "        Download a generated artifact file to local disk.\n",
    "        \n",
    "        Args:\n",
    "            session_id: The session ID that generated the file\n",
    "            filename: Name of the file to download (can include subdirectory, e.g., 'temp_charts/chart.png')\n",
    "            save_to: Local path to save the file (default: current directory with original filename)\n",
    "        \n",
    "        Returns:\n",
    "            str: Path to the downloaded file\n",
    "        \n",
    "        Example:\n",
    "            client.download_artifact(session_id, \"Warpage_Report_20250126.pptx\", \"./downloads/report.pptx\")\n",
    "        \"\"\"\n",
    "        r = httpx.get(\n",
    "            f\"{self.base_url}/api/chat/sessions/{session_id}/artifacts/{filename}\",\n",
    "            headers=self._headers(),\n",
    "            timeout=60.0\n",
    "        )\n",
    "        r.raise_for_status()\n",
    "        \n",
    "        # Determine local save path\n",
    "        if save_to is None:\n",
    "            save_to = Path(filename).name  # Use just the filename, not subdirectory\n",
    "        \n",
    "        # Create parent directories if needed\n",
    "        save_path = Path(save_to)\n",
    "        save_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Write file content\n",
    "        with open(save_path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        \n",
    "        return str(save_path)\n",
    "\n",
    "# Configuration\n",
    "API_BASE_URL = 'http://10.198.112.203:10007'\n",
    "USERNAME = \"ppt\"\n",
    "PASSWORD = \"ppt\"\n",
    "\n",
    "# Initialize and login\n",
    "client = LLMApiClient(API_BASE_URL, timeout=36000000.0)# 10 hours\n",
    "client.login(USERNAME, PASSWORD)\n",
    "models = client.list_models()\n",
    "MODEL = models[\"data\"][0][\"id\"]\n",
    "\n",
    "print(f\"✓ Logged in as: {USERNAME}\")\n",
    "print(f\"✓ Using model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f74a35",
   "metadata": {},
   "outputs": [],
   "source": "import os\n\n# ML CODE DIRECTORY (expanduser handles ~ expansion)\nmother_dir = os.path.expanduser('~/scratch1/MeshGraphNets')\n# docs directory\ndocs_path = os.path.join(mother_dir, 'CONFIG_AND_EXECUTION_GUIDE.md')\n\n# Now make the LLM API read the docs and run the code\nprompt = f\"\"\"\nYou are executing a long-running hyperparameter tuning experiment for ML models.\n\n## Your Task\n1. Read the attached documentation file carefully\n2. Understand the configuration options and execution workflow\n3. Plan out the hyperparameter tuning experiment\n4. Build configuration file for the experiment with distinguishable output file\n5. Execute the ML code as described in the documentation parallelly\n\n## Important Requirements\n- **Working Directory**: All code should run from `{mother_dir}`\n- **Logging**: Use the log file implemented in the code and with timestamps, distinguish filenames with config\n- **Error Handling**: If a single hyperparameter combination fails, log the error and continue with the next combination\n- **Results**: Save final results to a CSV/JSON file with all hyperparameter combinations and their metrics\n\n## Execution Guidelines\n- Use `cd {mother_dir}` at the start of your Python code\n- Do NOT stop until all hyperparameter combinations are tested\n- At the end, provide a summary of the best hyperparameters found\n\nBegin by reading the documentation, then execute the training.\n\"\"\"\n\n# Send with the docs file attached\nresponse, session_id = client.chat_new(\n    model=MODEL,\n    user_message=prompt,\n    agent_type=\"react\",  # Use react agent for tool calling\n    files=[docs_path]\n)\n\n# Save session for recovery (important for multi-day runs)\nwith open(\"active_session.txt\", \"w\") as f:\n    f.write(session_id)\nprint(f\"Session ID saved: {session_id}\")\nprint(response)"
  },
  {
   "cell_type": "code",
   "id": "dj87ct7ym8c",
   "source": "# Check progress of ongoing experiment\n# Uncomment the line below to load session from file if kernel restarted\n# session_id = open(\"active_session.txt\").read().strip()\n\ncheck_prompt = \"\"\"\nReport current progress:\n1. How many hyperparameter combinations completed?\n2. Current best result so far?\n3. Any errors encountered?\n4. Estimated remaining time?\n\"\"\"\n\nresponse, _ = client.chat_continue(\n    model=MODEL,\n    session_id=session_id,\n    user_message=check_prompt,\n    agent_type=\"react\"\n)\nprint(response)",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "id": "l3g68e6ad7",
   "source": "# Download results after completion\n# Uncomment the line below to load session from file if kernel restarted\n# session_id = open(\"active_session.txt\").read().strip()\n\nartifacts = client.get_session_artifacts(session_id)\nprint(\"Available files:\", artifacts)\n\n# Download results (CSV, JSON, and log files)\nimport os\nos.makedirs(\"./results\", exist_ok=True)\n\nfor artifact in artifacts.get(\"files\", []):\n    if artifact.endswith(('.csv', '.json', '.log')):\n        local_path = client.download_artifact(session_id, artifact, f\"./results/{artifact}\")\n        print(f\"Downloaded: {local_path}\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}