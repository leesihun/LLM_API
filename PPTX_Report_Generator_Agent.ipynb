{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-Orchestrated PowerPoint Report Generator\n",
    "\n",
    "This notebook uses **your LLM API's agentic capabilities** to automatically generate comprehensive PowerPoint reports from warpage data.\n",
    "\n",
    "## How It Works\n",
    "\n",
    "Instead of hardcoding visualizations and slides, this notebook:\n",
    "1. **Uploads your data** to the LLM API\n",
    "2. **Sends strategic prompts** to the ReAct agent\n",
    "3. **Lets the agent autonomously**:\n",
    "   - Analyze the data\n",
    "   - Generate visualization code\n",
    "   - Execute the code\n",
    "   - Create PowerPoint slides\n",
    "   - Add charts and formatting\n",
    "\n",
    "**Key Advantage:** The AI adapts to your data structure, fixes errors automatically, and can suggest additional insights.\n",
    "\n",
    "**Technology Stack:**\n",
    "- Your LLM API (ReAct agent + python_coder tool)\n",
    "- python-pptx (auto-generated)\n",
    "- matplotlib/seaborn (auto-generated)\n",
    "\n",
    "**Supports:** Multiple datasets, automatic comparison, adaptive visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration\n",
    "\n",
    "USE THIS AS IT IS, NO NEED TO CHANGE!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import time\n",
    "\n",
    "# LLM API Client (from API_examples.ipynb)\n",
    "class LLMApiClient:\n",
    "    def __init__(self, base_url: str, timeout: float = 3600.0):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.token = None\n",
    "        self.timeout = httpx.Timeout(50.0, read=timeout, write=timeout, pool=timeout)\n",
    "\n",
    "    def _headers(self):\n",
    "        h = {}\n",
    "        if self.token:\n",
    "            h[\"Authorization\"] = f\"Bearer {self.token}\"\n",
    "        return h\n",
    "\n",
    "    def login(self, username: str, password: str):\n",
    "        r = httpx.post(f\"{self.base_url}/api/auth/login\", json={\n",
    "            \"username\": username, \"password\": password\n",
    "        }, timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        data = r.json()\n",
    "        self.token = data[\"access_token\"]\n",
    "        return data\n",
    "\n",
    "    def list_models(self):\n",
    "        headers = {\"Authorization\": f\"Bearer {self.token}\"} if self.token else {}\n",
    "        r = httpx.get(f\"{self.base_url}/v1/models\", headers=headers, timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def chat_new(self, model: str, user_message: str, agent_type: str = \"auto\", files: list = None):\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"messages\": json.dumps(messages),\n",
    "            \"agent_type\": agent_type\n",
    "        }\n",
    "        \n",
    "        files_to_upload = []\n",
    "        if files:\n",
    "            for file_path in files:\n",
    "                f = open(file_path, \"rb\")\n",
    "                files_to_upload.append((\"files\", (Path(file_path).name, f)))\n",
    "        \n",
    "        try:\n",
    "            r = httpx.post(\n",
    "                f\"{self.base_url}/v1/chat/completions\",\n",
    "                data=data,\n",
    "                files=files_to_upload if files_to_upload else None,\n",
    "                headers=self._headers(),\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "            result = r.json()\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"], result[\"x_session_id\"]\n",
    "        finally:\n",
    "            for _, (_, f) in files_to_upload:\n",
    "                f.close()\n",
    "\n",
    "    def chat_continue(self, model: str, session_id: str, user_message: str, agent_type: str = \"auto\", files: list = None):\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        data = {\n",
    "            \"model\": model,\n",
    "            \"messages\": json.dumps(messages),\n",
    "            \"session_id\": session_id,\n",
    "            \"agent_type\": agent_type\n",
    "        }\n",
    "        \n",
    "        files_to_upload = []\n",
    "        if files:\n",
    "            for file_path in files:\n",
    "                f = open(file_path, \"rb\")\n",
    "                files_to_upload.append((\"files\", (Path(file_path).name, f)))\n",
    "        \n",
    "        try:\n",
    "            r = httpx.post(\n",
    "                f\"{self.base_url}/v1/chat/completions\",\n",
    "                data=data,\n",
    "                files=files_to_upload if files_to_upload else None,\n",
    "                headers=self._headers(),\n",
    "                timeout=self.timeout\n",
    "            )\n",
    "            r.raise_for_status()\n",
    "            result = r.json()\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"], result[\"x_session_id\"]\n",
    "        finally:\n",
    "            for _, (_, f) in files_to_upload:\n",
    "                f.close()\n",
    "\n",
    "# Configuration\n",
    "API_BASE_URL = 'http://localhost:1007'\n",
    "USERNAME = \"leesihun\"\n",
    "PASSWORD = \"s.hun.lee\"\n",
    "\n",
    "# Initialize client\n",
    "client = LLMApiClient(API_BASE_URL, timeout=3600.0)\n",
    "print(f\"Client initialized: {API_BASE_URL}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Login and get model\n",
    "client.login(USERNAME, PASSWORD)\n",
    "models = client.list_models()\n",
    "MODEL = models[\"data\"][0][\"id\"]\n",
    "\n",
    "print(f\"Logged in as: {USERNAME}\")\n",
    "print(f\"Using model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Configure Data Files\n",
    "\n",
    "**Edit this cell** to specify your warpage statistics files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CONFIGURATION: Define your data files\n",
    "# ========================================\n",
    "\n",
    "# Option 1: Single file\n",
    "# stats_paths = [Path(f\"data/uploads/{USERNAME}/20251013_stats.json\")]\n",
    "\n",
    "# Option 2: Multiple files for comparison\n",
    "stats_paths = [\n",
    "    Path(f\"B8_1021_stats.json\"),\n",
    "    Path(f\"B8_1027_stats.json\"),\n",
    "]\n",
    "\n",
    "# Verify files exist\n",
    "print(f\"Configured {len(stats_paths)} data file(s):\\n\")\n",
    "\n",
    "\n",
    "for i, path in enumerate(stats_paths, 1):\n",
    "    if path.exists():\n",
    "        size_kb = path.stat().st_size / 1024\n",
    "        print(f\"  [{i}] {path.name} ({size_kb:.1f} KB) - OK\")\n",
    "    else:\n",
    "        print(f\"  [{i}] {path.name} - FILE NOT FOUND\")\n",
    "\n",
    "# Convert to strings for API\n",
    "file_paths_str = [str(p) for p in stats_paths]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Phase 1: Data Analysis (AI-Driven)\n",
    "\n",
    "Let the AI agent analyze your data and recommend visualizations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis_prompt = f\"\"\"\n",
    "I have {len(stats_paths)} warpage measurement dataset(s) attached as JSON files.\n",
    "\n",
    "The JSON file contains, numerous data, of which correspond to each files.\n",
    "Under 'files', there are information regarding each PCB.\n",
    "'min' means minimum z-height, whereas 'max' means maximum.\n",
    "'range' equals max_minus_min, which is the warpage valeu.\n",
    "mean, median, std, skewness, and kurtosis are the stats inside a single PCB board.\n",
    "the PCA values are calculated within each source_pdf. Keep that in mind, and irregularity assessment of PCA should be done by assessing both PCA values.\n",
    "Now, with these files in mind,\n",
    "\n",
    "TASK: Comprehensive Data Analysis\n",
    "\n",
    "Please perform the following analysis:\n",
    "\n",
    "1. **Calculate Key Statistics:**\n",
    "   - Total number of measurements across all datasets\n",
    "   - Overall mean, std, min, max, range\n",
    "   - Number of outliers by viewing PCA values as shown in pc1, pc2\n",
    "   - Dataset comparison between different production dates\n",
    "\n",
    "2. **Identify Visualization Needs:**\n",
    "   - What trends should be visualized?\n",
    "   - What comparisons are important?\n",
    "   - What outliers or anomalies should be highlighted?\n",
    "\n",
    "3. **Identify outliers:**\n",
    "   - Find which files are outliers. Give the full file names.\n",
    "   - Add reasons why those are outliers, considering many aspects.\n",
    "\n",
    "4. **Return Summary:**\n",
    "   Provide a clear summary with:\n",
    "   - Which data is better and why?\n",
    "   - Any concerns or interesting patterns found\n",
    "\n",
    "Be specific and data-driven in your recommendations.\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 1: DATA ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nUploading {len(stats_paths)} file(s) to AI agent...\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "analysis_result, session_id = client.chat_new(\n",
    "    MODEL,\n",
    "    analysis_prompt,\n",
    "    agent_type=\"auto\",  # Let agent decide (will likely use python_coder)\n",
    "    files=file_paths_str\n",
    ")\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nAnalysis completed in {elapsed:.1f}s\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"AI ANALYSIS RESULT\")\n",
    "print(\"=\" * 80)\n",
    "from IPython.display import display, Math, Latex\n",
    "display(Latex(analysis_result))\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Phase 2: Generate Visualizations (AI-Driven)\n",
    "\n",
    "Let the AI agent create all visualizations based on the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_prompt = f\"\"\"\n",
    "**PRIORITY: Use your Phase 1 analysis results first.**\n",
    "\n",
    "In Phase 1, you already analyzed {len(stats_paths)} warpage datasets and loaded all the data.\n",
    "You identified:\n",
    "- Outliers via PCA (pc1, pc2) analysis\n",
    "- Production date comparison results\n",
    "- Key statistics for all files (mean, std, min, max, range)\n",
    "- Specific outlier file names and their characteristics\n",
    "\n",
    "**USE THESE FINDINGS from your Phase 1 analysis - DO NOT re-analyze from scratch.**\n",
    "\n",
    "The attached files are ONLY for reference if you need to verify or re-check specific raw values.\n",
    "Your primary data source should be what you already calculated in Phase 1.\n",
    "\n",
    "TASK: Create High-Quality Visualizations with Outlier Classification (Good vs Bad)\n",
    "\n",
    "**CRITICAL REQUIREMENT:**\n",
    "From Phase 1, you identified outliers via PCA (pc1, pc2) analysis.\n",
    "Now you must classify these outliers as either GOOD QUALITY or BAD QUALITY based on warpage metrics.\n",
    "\n",
    "**Outlier Quality Classification Logic:**\n",
    "\n",
    "1. **Identify Spatial Outliers (PCA-based):**\n",
    "   - Use the PCA outliers you already identified in Phase 1\n",
    "   - Calculate distance from PCA cluster center: sqrt((pc1 - mean_pc1)^2 + (pc2 - mean_pc2)^2)\n",
    "   - Outliers = files with distance > 95th percentile (or similar threshold)\n",
    "\n",
    "2. **Classify Outlier Quality:**\n",
    "   \n",
    "   **BAD Quality Outliers (highest priority):**\n",
    "   - High absolute mean warpage (far from target 0)\n",
    "   - High standard deviation (high variability)\n",
    "   - High range (extreme fluctuations)\n",
    "   - Multiple quality issues combined\n",
    "   - **These are critical problems requiring immediate action**\n",
    "   \n",
    "   **GOOD Quality Outliers (rare but possible):**\n",
    "   - Spatial outliers but with good metrics:\n",
    "   - Low std, mean near 0, consistent measurements\n",
    "   - Unusual PCA position but acceptable warpage\n",
    "   - **These are acceptable, just unusual**\n",
    "   \n",
    "   **Normal (non-outliers):**\n",
    "   - Within normal PCA cluster\n",
    "   - Standard quality metrics\n",
    "\n",
    "**Required Visualizations:**\n",
    "\n",
    "**1. PCA Outlier Classification** (CRITICAL - save as: pca_outliers_classified.png)\n",
    "   - Scatter plot: PC1 vs PC2\n",
    "   - Color coding:\n",
    "     - Blue dots: Normal samples\n",
    "     - Orange dots: Good quality outliers (if any exist)\n",
    "     - RED dots: BAD quality outliers (CRITICAL)\n",
    "   - Point size: Proportional to warpage severity (larger = worse)\n",
    "   - Annotations: Label BAD outliers with their file_id or filename\n",
    "   - Legend: Clearly explain color coding\n",
    "   - Title: \"PCA-Based Outlier Classification: Quality Assessment\"\n",
    "\n",
    "**2. Bad Outlier Details** (save as: bad_outliers_detail.png)\n",
    "   - Create comparative visualization for BAD outliers:\n",
    "   - Option A: Bar chart comparing each bad outlier's metrics (mean, std, range) vs dataset average\n",
    "   - Option B: Small multiples showing each bad outlier's key statistics\n",
    "   - Include annotations explaining WHY each is bad:\n",
    "     - \"File_XX: High variability (std=87.89 vs avg=79.5)\"\n",
    "     - \"File_YY: Extreme mean (mean=-311 vs avg=-297)\"\n",
    "   - Use RED color scheme to emphasize problems\n",
    "\n",
    "**3. Production Date Comparison** (save as: production_comparison.png)\n",
    "   - Compare datasets by production date (extract from filenames or metadata)\n",
    "   - Show multiple metrics:\n",
    "     - Average mean warpage per date\n",
    "     - Average std deviation per date\n",
    "     - Number of bad outliers per date\n",
    "     - Overall quality score per date\n",
    "   - Use bar charts or grouped comparisons\n",
    "   - Highlight which production date has better quality\n",
    "   - Title: \"Production Date Quality Comparison\"\n",
    "\n",
    "**4. Additional Standard Charts** (create as appropriate based on data):\n",
    "\n",
    "   a. **Temporal Trends** (temporal_trends.png) - if applicable:\n",
    "      - Line chart: mean values over file sequence\n",
    "      - Add Â±1Ïƒ envelope\n",
    "      - Mark bad outliers with red X markers\n",
    "   \n",
    "   b. **Distribution Analysis** (distributions.png):\n",
    "      - 2x2 grid of histograms: mean, std, skewness, kurtosis\n",
    "      - Mark positions of bad outliers with red vertical lines\n",
    "   \n",
    "   c. **Control Chart** (control_chart.png):\n",
    "      - Mean values with Â±3Ïƒ control limits\n",
    "      - Highlight bad outliers in red\n",
    "   \n",
    "   d. **Box Plots** (boxplots.png):\n",
    "      - Show min/max/range, mean/median, std distributions\n",
    "      - Overlay bad outlier positions\n",
    "   \n",
    "   e. **Correlation Heatmap** (correlation_heatmap.png):\n",
    "      - Correlations between all metrics\n",
    "      - Annotate with coefficients\n",
    "\n",
    "**Technical Requirements:**\n",
    "- Save all charts to 'temp_charts/' directory (create if doesn't exist)\n",
    "- Use 300 DPI for all images\n",
    "- Professional color scheme:\n",
    "  - Normal: Blue (#1f77b4)\n",
    "  - Good outliers: Orange (#ff7f0e)\n",
    "  - BAD outliers: Red (#d62728)\n",
    "  - Other: Green (#2ca02c), Gray (#7f7f7f)\n",
    "- Set style: seaborn whitegrid\n",
    "- Add proper titles, labels, legends\n",
    "- Use tight_layout() before saving\n",
    "- Font sizes: Title 14pt, labels 12pt, annotations 10pt\n",
    "\n",
    "**Packages:**\n",
    "- matplotlib.pyplot\n",
    "- seaborn\n",
    "- pandas\n",
    "- numpy\n",
    "- scipy (for distance calculations)\n",
    "- sklearn.preprocessing.MinMaxScaler (if needed)\n",
    "\n",
    "**REQUIRED OUTPUT:**\n",
    "After generating all charts, provide:\n",
    "\n",
    "1. **List of Generated Files:**\n",
    "   - pca_outliers_classified.png - [brief description]\n",
    "   - bad_outliers_detail.png - [brief description]\n",
    "   - production_comparison.png - [brief description]\n",
    "   - [other charts].png - [brief descriptions]\n",
    "\n",
    "2. **Bad Outlier Summary** (for PowerPoint executive slide):\n",
    "   - List each BAD outlier with:\n",
    "     - File ID/name\n",
    "     - Specific reasons (e.g., \"High std: 87.89\", \"Extreme mean: -311.45\")\n",
    "     - Severity ranking (1=worst, 2=2nd worst, etc.)\n",
    "\n",
    "3. **Production Date Insights:**\n",
    "   - Which production date is better and why\n",
    "   - Quality metrics comparison\n",
    "\n",
    "4. **Key Insights for Executive Summary:**\n",
    "   - Total bad outliers count\n",
    "   - Most critical quality issue found\n",
    "   - Recommendation for immediate action\n",
    "\n",
    "Print confirmation after EACH chart is saved.\n",
    "Be thorough in classification - bad outliers need immediate attention!\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 2: VISUALIZATION GENERATION WITH OUTLIER CLASSIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nGenerating professional visualizations with quality assessment...\\n\")\n",
    "print(\"NOTE: Prioritizing Phase 1 analysis results, files available as fallback\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "viz_result, _ = client.chat_continue(\n",
    "    MODEL,\n",
    "    session_id,\n",
    "    visualization_prompt,\n",
    "    agent_type=\"auto\",\n",
    "    files=file_paths_str  # Keep as fallback reference\n",
    ")\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nVisualization generation completed in {elapsed:.1f}s\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"AI VISUALIZATION RESULT\")\n",
    "print(\"=\" * 80)\n",
    "display(Latex(viz_result))\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Phase 3: PowerPoint Assembly (AI-Driven)\n",
    "\n",
    "Let the AI agent create the PowerPoint presentation with all charts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total file count for the prompt\n",
    "total_files = 0\n",
    "for path in stats_paths:\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        total_files += len(data.get('files', []))\n",
    "\n",
    "pptx_prompt = f\"\"\"\n",
    "**PRIORITY: Use your Phase 1 & Phase 2 findings first.**\n",
    "\n",
    "In Phase 1, you analyzed {len(stats_paths)} warpage datasets and identified:\n",
    "- Key statistics (total measurements, mean, std, min, max, range)\n",
    "- Outliers via PCA (pc1, pc2) analysis\n",
    "- Production date comparison results\n",
    "- Specific outlier file names and characteristics\n",
    "\n",
    "In Phase 2, you classified outliers and generated visualizations:\n",
    "- BAD quality outliers (high mean/std/range - critical issues)\n",
    "- GOOD quality outliers (unusual PCA but acceptable metrics)\n",
    "- Created charts in temp_charts/ directory\n",
    "- Provided bad outlier summary with specific file IDs and reasons\n",
    "\n",
    "**USE THESE FINDINGS from Phase 1 & 2 - DO NOT re-analyze the raw data files.**\n",
    "\n",
    "The attached files are ONLY for reference if you need to verify specific values.\n",
    "Your primary information sources are:\n",
    "1. Phase 1 analysis results (conversation context)\n",
    "2. Phase 2 visualization results and bad outlier classifications (conversation context)\n",
    "3. Generated PNG charts in temp_charts/ directory\n",
    "\n",
    "TASK: Create a professional PowerPoint presentation using python-pptx with CRITICAL FOCUS on bad quality outliers.\n",
    "\n",
    "**CONTEXT FROM PREVIOUS PHASES:**\n",
    "- Phase 1: Identified outliers via PCA analysis and compared production dates\n",
    "- Phase 2: Classified outliers as GOOD or BAD quality\n",
    "- Phase 2: Generated visualizations in temp_charts/ directory\n",
    "- Phase 2: Provided bad outlier summary and production date insights\n",
    "\n",
    "**CRITICAL REQUIREMENT:**\n",
    "The FIRST CONTENT SLIDE (Slide 2) must prominently display BAD OUTLIERS as an alert/warning.\n",
    "Bad outliers require immediate attention and must be visible immediately.\n",
    "\n",
    "**Presentation Details:**\n",
    "- Title: \"Warpage Analysis Report\"\n",
    "- Subtitle: \"Statistical Analysis of {total_files} Measurement Files ({len(stats_paths)} Production Dates)\"\n",
    "- Slide size: 10 x 7.5 inches\n",
    "- Output filename: Warpage_Report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.pptx\n",
    "\n",
    "**MANDATORY SLIDE STRUCTURE:**\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "**Slide 1: Title Slide**\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "- Title: \"Warpage Analysis Report\" (44pt, bold, blue #1f77b4, centered)\n",
    "- Subtitle: \"Statistical Analysis of {total_files} Measurement Files ({len(stats_paths)} Production Dates)\" (24pt, centered)\n",
    "- Date: {datetime.now().strftime('%Y-%m-%d')} (14pt, italic, centered)\n",
    "- Use blank layout (index 6)\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "**Slide 2: EXECUTIVE SUMMARY - QUALITY ALERT** âš ï¸ CRITICAL SLIDE\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "**This is the MOST IMPORTANT slide - bad outliers must be prominently featured**\n",
    "\n",
    "**Layout Structure (top to bottom):**\n",
    "\n",
    "1. **Title** (top of slide, 0.3 inches from top):\n",
    "   - Text: \"Executive Summary - Quality Alert\"\n",
    "   - Font: 32pt, bold, RED (#d62728)\n",
    "   - Alignment: CENTER\n",
    "\n",
    "2. **RED ALERT BOX** (1.0 inch from top, 9 inches wide, 0.5 inches from left):\n",
    "   - Shape: Rectangle with RED fill (#d62728)\n",
    "   - Border: White, 2pt\n",
    "   - Height: Auto-size based on content (min 1.5 inches)\n",
    "   \n",
    "   **Inside Alert Box (white text on red background):**\n",
    "   - Header: \"âš  BAD QUALITY OUTLIERS IDENTIFIED\" (20pt, bold, white)\n",
    "   - Subheader: \"Immediate Action Required\" (14pt, white)\n",
    "   - **List of Bad Outliers** (extracted from Phase 2 results in conversation context):\n",
    "     - Each outlier on new line with bullet point\n",
    "     - Format: \"â€¢ [File ID/Name]: [Reason 1], [Reason 2]\" (12pt, white)\n",
    "     - Example: \"â€¢ File_04_B8_1021: High variability (std=87.89), Extreme mean (-311.45)\"\n",
    "     - List ALL bad outliers identified by Phase 2 (from your conversation memory)\n",
    "   - If no bad outliers: \"âœ“ No critical quality issues detected\" (16pt, white)\n",
    "\n",
    "3. **KEY METRICS CARDS** (below alert box, ~3.0 inches from top):\n",
    "   - 4 colored metric cards in a row (each 2 inches wide, 1.2 inches tall)\n",
    "   - Card positions: 0.5, 2.8, 5.1, 7.4 inches from left\n",
    "   \n",
    "   **Card 1 (Blue background #1f77b4):**\n",
    "   - Value: \"{total_files}\" (28pt, bold, white, centered)\n",
    "   - Label: \"Total Measurements\" (11pt, white, centered)\n",
    "   \n",
    "   **Card 2 (Green background #2ca02c if winner, Orange #ff7f0e if loser):**\n",
    "   - Value: \"[Production Date from Phase 1 conversation]\" (24pt, bold, white, centered)\n",
    "   - Label: \"Better Production Date\" (11pt, white, centered)\n",
    "   \n",
    "   **Card 3 (Red background #d62728):**\n",
    "   - Value: \"[Bad outlier count from Phase 2 conversation]\" (28pt, bold, white, centered)\n",
    "   - Label: \"Bad Outliers\" (11pt, white, centered)\n",
    "   \n",
    "   **Card 4 (Orange background #ff7f0e):**\n",
    "   - Value: \"[Avg mean from Phase 1 conversation]\" (24pt, bold, white, centered)\n",
    "   - Label: \"Avg Mean Warpage\" (11pt, white, centered)\n",
    "\n",
    "4. **PRODUCTION DATE COMPARISON** (below cards, ~4.5 inches from top):\n",
    "   - Textbox: 0.5 inches from left, 8.5 inches wide\n",
    "   - Title: \"Production Date Analysis:\" (16pt, bold, black)\n",
    "   - Content from Phase 1 analysis (conversation context):\n",
    "     - \"[Date 1]: [Quality assessment]\"\n",
    "     - \"[Date 2]: [Quality assessment]\"\n",
    "     - \"Winner: [Date] - Reason: [from Phase 1]\"\n",
    "   - Font: 12pt, black\n",
    "\n",
    "5. **KEY INSIGHTS** (bottom section, ~5.5 inches from top):\n",
    "   - Textbox: 0.5 inches from left, 8.5 inches wide\n",
    "   - Title: \"Critical Findings:\" (14pt, bold, black)\n",
    "   - Bullet points from Phase 1 & 2 analysis (12pt):\n",
    "     - Most critical quality issue\n",
    "     - Overall data quality assessment\n",
    "     - Recommended immediate actions\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "**Slide 3: PCA-Based Outlier Classification**\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "- Title: \"Outlier Classification: Quality Assessment\" (28pt, bold, blue)\n",
    "- Image: temp_charts/pca_outliers_classified.png (9 inches wide, centered, 1 inch from top of content area)\n",
    "- Description textbox (below image, 0.5 inch margin):\n",
    "  - \"Color Coding:\" (12pt, bold)\n",
    "  - \"â€¢ Blue: Normal quality samples\"\n",
    "  - \"â€¢ Orange: Good outliers (unusual but acceptable)\"\n",
    "  - \"â€¢ RED: BAD outliers (require immediate action)\"\n",
    "  - Font: 11pt\n",
    "- **List bad outliers again** (below description):\n",
    "  - \"Critical Files:\" (12pt, bold, red)\n",
    "  - Extract from Phase 2 conversation: list file IDs/names with issues (11pt)\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "**Slide 4: Bad Outlier Detailed Analysis**\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "- Title: \"Detailed Analysis: Bad Quality Outliers\" (28pt, bold, red #d62728)\n",
    "- Image: temp_charts/bad_outliers_detail.png (if exists, 9 inches wide, centered)\n",
    "- Description textbox:\n",
    "  - Title: \"Why These Samples Failed Quality Standards:\" (14pt, bold, black)\n",
    "  - For EACH bad outlier (from Phase 2 summary in conversation):\n",
    "    - \"â€¢ [File ID]: [Detailed explanation]\"\n",
    "    - Include specific metrics (mean, std, range values)\n",
    "    - Compare to dataset average\n",
    "  - Font: 11pt\n",
    "- Action items textbox (bottom of slide):\n",
    "  - Title: \"Required Actions:\" (14pt, bold, red)\n",
    "  - Bullet points:\n",
    "    - \"Root cause analysis for each bad outlier\"\n",
    "    - \"Review manufacturing process at time of measurement\"\n",
    "    - \"Implement corrective actions\"\n",
    "  - Font: 12pt\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "**Slide 5: Production Date Quality Comparison**\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "- Title: \"Production Date Comparison\" (28pt, bold, blue)\n",
    "- Image: temp_charts/production_comparison.png (9 inches wide, centered)\n",
    "- Summary textbox (below image):\n",
    "  - From Phase 1 analysis conversation:\n",
    "    - \"Better Production Date: [Date] - [Reason]\"\n",
    "    - \"Quality Metrics Comparison: [Details]\"\n",
    "    - \"Recommendation: [Process improvement suggestion]\"\n",
    "  - Font: 12pt\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "**Slides 6+: Additional Visualizations (ADAPTIVE)**\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "**IMPORTANT: Discover and add slides for ALL remaining charts in temp_charts/**\n",
    "\n",
    "For each additional PNG file found in temp_charts/ (besides those already used):\n",
    "- Create a new slide with blank layout\n",
    "- Add title based on filename (convert underscore to space, title case)\n",
    "  - Example: \"temporal_trends.png\" â†’ \"Temporal Trends\"\n",
    "- Add image (9 inches wide, centered)\n",
    "- Add brief description based on chart type:\n",
    "  - temporal_trends: \"Mean warpage values over measurement sequence with variability envelope\"\n",
    "  - distributions: \"Statistical distribution analysis across all metrics\"\n",
    "  - control_chart: \"Statistical process control with Â±3Ïƒ limits\"\n",
    "  - boxplots: \"Variability analysis showing spread and quartiles\"\n",
    "  - correlation_heatmap: \"Metric correlations (values close to Â±1 indicate strong relationships)\"\n",
    "  - [other charts]: Provide appropriate description\n",
    "\n",
    "**Common charts that might exist:**\n",
    "- temporal_trends.png\n",
    "- distributions.png\n",
    "- control_chart.png\n",
    "- boxplots.png\n",
    "- correlation_heatmap.png\n",
    "- summary_table.png\n",
    "- etc.\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "**FINAL SLIDE: Recommendations & Action Items**\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "- Title: \"Recommendations & Action Items\" (32pt, bold, blue)\n",
    "\n",
    "**Section 1: IMMEDIATE ACTIONS** (0.8 inches from top):\n",
    "- Header: \"ğŸ”´ IMMEDIATE ACTIONS REQUIRED\" (18pt, bold, red #d62728)\n",
    "- Bullets (12pt):\n",
    "  - \"Investigate bad outlier files: [list specific files from Phase 2 conversation]\"\n",
    "  - \"Root cause analysis for [production date with worse quality from Phase 1]\"\n",
    "  - \"Implement corrective actions based on findings\"\n",
    "  - \"Quarantine or retest affected samples\"\n",
    "\n",
    "**Section 2: QUALITY IMPROVEMENT** (~2.5 inches from top):\n",
    "- Header: \"ğŸ“Š Quality Improvement Strategy\" (18pt, bold, orange #ff7f0e)\n",
    "- Bullets (12pt, based on Phase 1 findings from conversation):\n",
    "  - \"Replicate best practices from [better production date]\"\n",
    "  - \"Target metrics: Mean near 0, Std < [threshold from best batch]\"\n",
    "  - \"Reduce variability through process optimization\"\n",
    "  - \"Focus on [specific issue found in Phase 1]\"\n",
    "\n",
    "**Section 3: MONITORING & PREVENTION** (~4.5 inches from top):\n",
    "- Header: \"ğŸ” Ongoing Monitoring\" (18pt, bold, blue #1f77b4)\n",
    "- Bullets (12pt):\n",
    "  - \"Implement PCA-based outlier detection system\"\n",
    "  - \"Set automated alerts for quality deviations (Â±3Ïƒ limits)\"\n",
    "  - \"Conduct weekly quality reviews\"\n",
    "  - \"Track improvement metrics over time\"\n",
    "\n",
    "**Section 4: SUMMARY** (bottom, ~6.0 inches from top):\n",
    "- Textbox with gray background (#f0f0f0):\n",
    "  - \"Based on this analysis of {total_files} measurements across {len(stats_paths)} production dates:\"\n",
    "  - \"â€¢ [Count] bad outliers identified requiring immediate action\"\n",
    "  - \"â€¢ Production date [winner] shows superior quality\"\n",
    "  - \"â€¢ Recommended focus: [key issue from Phase 1]\"\n",
    "  - Font: 11pt, black\n",
    "\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "**TECHNICAL REQUIREMENTS:**\n",
    "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "- Use blank layout (index 6) for all slides\n",
    "- RGB colors: Blue (31,119,180), Orange (255,127,14), Green (44,160,44), Red (214,39,40)\n",
    "- All titles: PP_ALIGN.CENTER\n",
    "- All textboxes: 0.5 inch margins unless specified\n",
    "- Image dimensions: 9 inches wide (height auto-scale maintaining aspect ratio)\n",
    "- Shape fills: Use .fill.solid() then .fill.fore_color.rgb = RGBColor(...)\n",
    "- Text in shapes: Use separate textbox overlays with white text\n",
    "\n",
    "**CRITICAL IMPLEMENTATION NOTES:**\n",
    "1. **PRIORITY**: Extract bad outlier information from Phase 2 results in conversation context (not from files)\n",
    "2. **PRIORITY**: Extract production date comparison from Phase 1 results in conversation context (not from files)\n",
    "3. Scan temp_charts/ directory to find all PNG files\n",
    "4. Adapt slide count based on charts found (don't hardcode exact number)\n",
    "5. Ensure bad outliers appear prominently on Slides 2, 3, and 4\n",
    "6. Make RED ALERT BOX on Slide 2 highly visible and impactful\n",
    "7. Link all insights from Phase 1 and Phase 2 throughout presentation\n",
    "8. **Files are ONLY for fallback reference - use conversation memory first**\n",
    "\n",
    "**OUTPUT REQUIREMENTS:**\n",
    "Print after completion:\n",
    "- Filename: [full path]\n",
    "- File size: [KB]\n",
    "- Total slides: [count]\n",
    "- Bad outliers highlighted: [list]\n",
    "- Charts included: [list all PNG files used]\n",
    "\n",
    "**REMEMBER:**\n",
    "- Slide 2 is the MOST IMPORTANT - bad outliers must be IMMEDIATELY VISIBLE\n",
    "- Use information from Phase 1 (analysis_result) and Phase 2 (viz_result) in conversation\n",
    "- Be thorough - this report drives quality improvement decisions!\n",
    "\"\"\"\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"PHASE 3: POWERPOINT ASSEMBLY WITH OUTLIER FOCUS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nCreating PowerPoint with bad outlier alert as priority...\\n\")\n",
    "print(\"NOTE: Prioritizing Phase 1 & 2 conversation findings, files available as fallback\\n\")\n",
    "\n",
    "start_time = time.time()\n",
    "pptx_result, _ = client.chat_continue(\n",
    "    MODEL,\n",
    "    session_id,\n",
    "    pptx_prompt,\n",
    "    agent_type=\"auto\",\n",
    "    files=file_paths_str  # Keep as fallback reference\n",
    ")\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"\\nPowerPoint creation completed in {elapsed:.1f}s\\n\")\n",
    "print(\"=\" * 80)\n",
    "print(\"AI POWERPOINT RESULT\")\n",
    "print(\"=\" * 80)\n",
    "display(Latex(pptx_result))\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Summary & Next Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import glob\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"REPORT GENERATION COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Find generated PowerPoint\n",
    "pptx_files = sorted(glob.glob(\"Warpage_Report_*.pptx\"), reverse=True)\n",
    "if pptx_files:\n",
    "    latest_pptx = pptx_files[0]\n",
    "    size_kb = Path(latest_pptx).stat().st_size / 1024\n",
    "    print(f\"\\nGenerated PowerPoint:\")\n",
    "    print(f\"  File: {latest_pptx}\")\n",
    "    print(f\"  Size: {size_kb:.2f} KB\")\n",
    "else:\n",
    "    print(\"\\nWarning: Could not find generated PowerPoint file\")\n",
    "\n",
    "# Check generated charts\n",
    "temp_charts = Path(\"temp_charts\")\n",
    "if temp_charts.exists():\n",
    "    chart_files = list(temp_charts.glob(\"*.png\"))\n",
    "    print(f\"\\nGenerated Charts: {len(chart_files)}\")\n",
    "    for chart in sorted(chart_files):\n",
    "        print(f\"  - {chart.name}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"WHAT THE AI DID\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "Phase 1: Data Analysis\n",
    "  - Loaded and combined all datasets\n",
    "  - Calculated key statistics\n",
    "  - Identified patterns and outliers\n",
    "  - Recommended visualizations\n",
    "\n",
    "Phase 2: Visualization Generation\n",
    "  - Generated 8-9 professional charts\n",
    "  - Used matplotlib/seaborn with 300 DPI\n",
    "  - Applied professional color schemes\n",
    "  - Saved all charts to temp_charts/\n",
    "\n",
    "Phase 3: PowerPoint Assembly\n",
    "  - Created 11-12 slide presentation\n",
    "  - Added title, summary, charts, and recommendations\n",
    "  - Formatted with professional styling\n",
    "  - Saved with timestamp\n",
    "\n",
    "Total Steps: All autonomous via ReAct agent + python_coder tool!\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\"\"\n",
    "1. Open the generated .pptx file\n",
    "2. Review charts and insights\n",
    "3. Customize branding/colors if needed\n",
    "4. Add company logo\n",
    "5. Present to stakeholders\n",
    "\n",
    "To regenerate with different data:\n",
    "  - Update stats_paths in Section 2\n",
    "  - Run all cells again\n",
    "\n",
    "To cleanup temporary files:\n",
    "  - Delete temp_charts/ directory\n",
    "  - Delete old .pptx files\n",
    "\"\"\")\n",
    "\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Optional: Cleanup\n",
    "\n",
    "Remove temporary chart files if desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## About This Notebook\n",
    "\n",
    "This notebook demonstrates the power of **AI-orchestrated automation**:\n",
    "\n",
    "- **~200 lines of orchestration code** vs 2000+ lines of hardcoded logic\n",
    "- **Adaptive**: AI adjusts to your data structure\n",
    "- **Self-healing**: Auto-fixes code errors (max 5 retries)\n",
    "- **Multi-file support**: Built-in from your API\n",
    "- **Leverages your infrastructure**: ReAct agent + python_coder tool\n",
    "\n",
    "**How it works:**\n",
    "1. You provide strategic prompts\n",
    "2. ReAct agent reasons about the task\n",
    "3. python_coder generates code\n",
    "4. Code executes in sandboxed environment\n",
    "5. Agent verifies results and iterates if needed\n",
    "\n",
    "**Result:** Comprehensive PowerPoint report generated autonomously!\n",
    "\n",
    "---\n",
    "\n",
    "**Version:** 1.0.0 (AI-Orchestrated)  \n",
    "**Last Updated:** January 2025"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
