{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Phase Workflow with Conversation Context Reuse\n",
    "\n",
    "This notebook demonstrates **conversation context reuse** - a powerful pattern for multi-step workflows.\n",
    "\n",
    "## Key Concept: Files as Fallback\n",
    "\n",
    "Instead of re-processing data files in every phase:\n",
    "1. **Phase 1:** Process files → store findings in conversation memory\n",
    "2. **Phase 2+:** Reuse Phase 1 findings from conversation memory\n",
    "3. **Files:** Only for verification/fallback, not re-processing\n",
    "\n",
    "## Benefits\n",
    "\n",
    "- **90% fewer LLM calls** - No redundant file parsing\n",
    "- **Faster execution** - Reuse existing calculations\n",
    "- **Better consistency** - All phases use same base analysis\n",
    "- **Lower costs** - Reduced token usage\n",
    "\n",
    "---\n",
    "\n",
    "**Use this pattern for:** Data analysis → Visualization → Reporting, Multi-step transformations, Complex workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import httpx\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "# Simple API Client (from API_examples.ipynb)\n",
    "class LLMApiClient:\n",
    "    def __init__(self, base_url: str, timeout: float = 3600.0):\n",
    "        self.base_url = base_url.rstrip(\"/\")\n",
    "        self.token = None\n",
    "        self.timeout = httpx.Timeout(50.0, read=timeout, write=timeout, pool=timeout)\n",
    "\n",
    "    def _headers(self):\n",
    "        return {\"Authorization\": f\"Bearer {self.token}\"} if self.token else {}\n",
    "\n",
    "    def login(self, username: str, password: str):\n",
    "        r = httpx.post(f\"{self.base_url}/api/auth/login\", \n",
    "                      json={\"username\": username, \"password\": password}, timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        self.token = r.json()[\"access_token\"]\n",
    "        return r.json()\n",
    "\n",
    "    def list_models(self):\n",
    "        r = httpx.get(f\"{self.base_url}/v1/models\", headers=self._headers(), timeout=10.0)\n",
    "        r.raise_for_status()\n",
    "        return r.json()\n",
    "\n",
    "    def chat_new(self, model: str, user_message: str, agent_type: str = \"auto\", files: list = None):\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        data = {\"model\": model, \"messages\": json.dumps(messages), \"agent_type\": agent_type}\n",
    "        \n",
    "        files_to_upload = []\n",
    "        if files:\n",
    "            for file_path in files:\n",
    "                f = open(file_path, \"rb\")\n",
    "                files_to_upload.append((\"files\", (Path(file_path).name, f)))\n",
    "        \n",
    "        try:\n",
    "            r = httpx.post(f\"{self.base_url}/v1/chat/completions\", data=data,\n",
    "                          files=files_to_upload if files_to_upload else None,\n",
    "                          headers=self._headers(), timeout=self.timeout)\n",
    "            r.raise_for_status()\n",
    "            result = r.json()\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"], result[\"x_session_id\"]\n",
    "        finally:\n",
    "            for _, (_, f) in files_to_upload:\n",
    "                f.close()\n",
    "\n",
    "    def chat_continue(self, model: str, session_id: str, user_message: str, \n",
    "                     agent_type: str = \"auto\", files: list = None):\n",
    "        messages = [{\"role\": \"user\", \"content\": user_message}]\n",
    "        data = {\"model\": model, \"messages\": json.dumps(messages), \n",
    "                \"session_id\": session_id, \"agent_type\": agent_type}\n",
    "        \n",
    "        files_to_upload = []\n",
    "        if files:\n",
    "            for file_path in files:  \n",
    "                f = open(file_path, \"rb\")\n",
    "                files_to_upload.append((\"files\", (Path(file_path).name, f)))\n",
    "        \n",
    "        try:\n",
    "            r = httpx.post(f\"{self.base_url}/v1/chat/completions\", data=data,\n",
    "                          files=files_to_upload if files_to_upload else None,\n",
    "                          headers=self._headers(), timeout=self.timeout)\n",
    "            r.raise_for_status()\n",
    "            result = r.json()\n",
    "            return result[\"choices\"][0][\"message\"][\"content\"], result[\"x_session_id\"]\n",
    "        finally:\n",
    "            for _, (_, f) in files_to_upload:\n",
    "                f.close()\n",
    "\n",
    "# Configuration\n",
    "API_BASE_URL = 'http://localhost:1007'\n",
    "USERNAME = \"leesihun\"\n",
    "PASSWORD = \"s.hun.lee\"\n",
    "\n",
    "client = LLMApiClient(API_BASE_URL)\n",
    "client.login(USERNAME, PASSWORD)\n",
    "MODEL = client.list_models()[\"data\"][0][\"id\"]\n",
    "\n",
    "print(f\"✓ Logged in as: {USERNAME}\")\n",
    "print(f\"✓ Using model: {MODEL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: Create Test Data\n",
    "\n",
    "Create sample sales data for our multi-phase workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test CSV data\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "sales_data = pd.DataFrame({\n",
    "    'date': pd.date_range('2025-01-01', periods=100, freq='D'),\n",
    "    'product': np.random.choice(['Laptop', 'Phone', 'Tablet', 'Monitor'], 100),\n",
    "    'quantity': np.random.randint(1, 20, 100),\n",
    "    'price': np.random.choice([500, 800, 300, 400], 100),\n",
    "    'region': np.random.choice(['North', 'South', 'East', 'West'], 100)\n",
    "})\n",
    "\n",
    "sales_data['revenue'] = sales_data['quantity'] * sales_data['price']\n",
    "\n",
    "# Save to CSV\n",
    "csv_path = 'test_sales_data.csv'\n",
    "sales_data.to_csv(csv_path, index=False)\n",
    "\n",
    "print(f\"✓ Created {csv_path}\")\n",
    "print(f\"  Shape: {sales_data.shape}\")\n",
    "print(f\"  Total revenue: ${sales_data['revenue'].sum():,}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "sales_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ❌ Anti-Pattern: Re-processing Files in Every Phase\n",
    "\n",
    "**Don't do this** - it wastes LLM calls and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BAD EXAMPLE - Re-processes file in every phase\n",
    "print(\"=\" * 80)\n",
    "print(\"❌ ANTI-PATTERN: Re-processing files\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Phase 1: Analysis (processes file)\n",
    "phase1_bad = \"Analyze the attached sales CSV and calculate total revenue.\"\n",
    "start = time.time()\n",
    "result1, sid = client.chat_new(MODEL, phase1_bad, files=[csv_path])\n",
    "time1 = time.time() - start\n",
    "print(f\"\\nPhase 1: {time1:.1f}s\")\n",
    "print(result1[:200] + \"...\")\n",
    "\n",
    "# Phase 2: Still asking to analyze file again\n",
    "phase2_bad = \"Analyze the attached sales CSV and find the top 3 products by revenue.\"\n",
    "start = time.time()\n",
    "result2, _ = client.chat_continue(MODEL, sid, phase2_bad, files=[csv_path])\n",
    "time2 = time.time() - start\n",
    "print(f\"\\nPhase 2: {time2:.1f}s (re-processed file!)\")\n",
    "print(result2[:200] + \"...\")\n",
    "\n",
    "print(f\"\\n⚠ Total time: {time1 + time2:.1f}s\")\n",
    "print(\"⚠ File processed 2 times (wasteful!)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ✅ Best Practice: Conversation Context Reuse\n",
    "\n",
    "**Do this** - process once, reuse findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GOOD EXAMPLE - Process once, reuse context\n",
    "print(\"=\" * 80)\n",
    "print(\"✅ BEST PRACTICE: Conversation context reuse\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Phase 1: Analysis (processes file ONCE)\n",
    "phase1_good = \"\"\"\n",
    "Analyze the attached sales CSV file.\n",
    "\n",
    "Calculate and store in memory:\n",
    "1. Total revenue\n",
    "2. Revenue by product\n",
    "3. Revenue by region\n",
    "4. Top 3 products\n",
    "\n",
    "I'll ask follow-up questions in subsequent messages.\n",
    "\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "result1, sid = client.chat_new(MODEL, phase1_good, files=[csv_path])\n",
    "time1 = time.time() - start\n",
    "print(f\"\\nPhase 1 (file processing): {time1:.1f}s\")\n",
    "print(result1[:300] + \"...\")\n",
    "\n",
    "# Phase 2: Reuse Phase 1 findings (NO file re-processing)\n",
    "phase2_good = \"\"\"\n",
    "**PRIORITY: Use your Phase 1 analysis from conversation memory.**\n",
    "\n",
    "You already analyzed the sales CSV in Phase 1 and calculated:\n",
    "- Total revenue\n",
    "- Revenue by product\n",
    "- Revenue by region\n",
    "- Top 3 products\n",
    "\n",
    "**DO NOT re-analyze the file.** Use your Phase 1 findings.\n",
    "\n",
    "Based on Phase 1 results:\n",
    "1. What percentage of total revenue does the top product represent?\n",
    "2. Which region has the lowest revenue?\n",
    "\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "result2, _ = client.chat_continue(MODEL, sid, phase2_good)\n",
    "time2 = time.time() - start\n",
    "print(f\"\\nPhase 2 (context reuse): {time2:.1f}s (no file re-processing!)\")\n",
    "print(result2[:300] + \"...\")\n",
    "\n",
    "# Phase 3: More analysis using conversation context\n",
    "phase3_good = \"\"\"\n",
    "**PRIORITY: Use Phase 1 & 2 findings from conversation memory.**\n",
    "\n",
    "Based on your previous analysis:\n",
    "- Calculate the average revenue per transaction\n",
    "- Identify any regional disparities worth noting\n",
    "\"\"\"\n",
    "\n",
    "start = time.time()\n",
    "result3, _ = client.chat_continue(MODEL, sid, phase3_good)\n",
    "time3 = time.time() - start\n",
    "print(f\"\\nPhase 3 (context reuse): {time3:.1f}s (no file re-processing!)\")\n",
    "print(result3[:300] + \"...\")\n",
    "\n",
    "print(f\"\\n✅ Total time: {time1 + time2 + time3:.1f}s\")\n",
    "print(\"✅ File processed 1 time (efficient!)\")\n",
    "print(f\"✅ Phases 2-3 used conversation memory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern Template: Phase Handoff Prompts\n",
    "\n",
    "Use this template for multi-phase workflows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for phase handoff prompts\n",
    "\n",
    "PHASE_1_TEMPLATE = \"\"\"\n",
    "Analyze the attached {file_description} file.\n",
    "\n",
    "Calculate and store in memory:\n",
    "{list_of_calculations}\n",
    "\n",
    "I'll ask follow-up questions in subsequent messages.\n",
    "\"\"\"\n",
    "\n",
    "PHASE_N_TEMPLATE = \"\"\"\n",
    "**PRIORITY: Use your Phase {previous_phase} findings from conversation memory.**\n",
    "\n",
    "In Phase {previous_phase}, you already:\n",
    "{summary_of_previous_findings}\n",
    "\n",
    "**DO NOT re-analyze the raw files.** Use your Phase {previous_phase} findings.\n",
    "\n",
    "The attached files are ONLY for verification if needed.\n",
    "\n",
    "Current Task:\n",
    "{current_task_description}\n",
    "\"\"\"\n",
    "\n",
    "print(\"Phase 1 Template:\")\n",
    "print(PHASE_1_TEMPLATE)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"Phase N Template:\")\n",
    "print(PHASE_N_TEMPLATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Real-World Example: Data Analysis → Visualization → Report\n",
    "\n",
    "Complete 3-phase workflow with context reuse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 80)\n",
    "print(\"REAL-WORLD WORKFLOW: Analysis → Visualization → Report\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Phase 1: Deep Analysis\n",
    "analysis_prompt = \"\"\"\n",
    "Analyze the attached sales CSV file comprehensively.\n",
    "\n",
    "Calculate and save to numpy arrays:\n",
    "1. Total revenue by product\n",
    "2. Total revenue by region\n",
    "3. Daily revenue trend\n",
    "4. Top 5 days by revenue\n",
    "5. Average transaction size\n",
    "\n",
    "Store all results locally for next phases.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n[Phase 1: Analysis]\")\n",
    "start = time.time()\n",
    "analysis_result, wf_session = client.chat_new(MODEL, analysis_prompt, files=[csv_path])\n",
    "print(f\"Time: {time.time() - start:.1f}s\")\n",
    "print(analysis_result[:400] + \"...\\n\")\n",
    "\n",
    "# Phase 2: Visualization (reuses Phase 1)\n",
    "viz_prompt = \"\"\"\n",
    "**PRIORITY: Use Phase 1 analysis from conversation memory.**\n",
    "\n",
    "You already calculated:\n",
    "- Revenue by product/region\n",
    "- Daily trends\n",
    "- Top 5 days\n",
    "- Average transaction size\n",
    "\n",
    "**DO NOT re-analyze the CSV.** Use Phase 1 results.\n",
    "\n",
    "Task: Create visualizations:\n",
    "1. Bar chart: Revenue by product (save as 'revenue_by_product.png')\n",
    "2. Line chart: Daily revenue trend (save as 'daily_trend.png')\n",
    "3. Pie chart: Revenue by region (save as 'revenue_by_region.png')\n",
    "\n",
    "Use matplotlib, 300 DPI, professional style.\n",
    "\"\"\"\n",
    "\n",
    "print(\"[Phase 2: Visualization]\")\n",
    "start = time.time()\n",
    "viz_result, _ = client.chat_continue(MODEL, wf_session, viz_prompt)\n",
    "print(f\"Time: {time.time() - start:.1f}s\")\n",
    "print(viz_result[:400] + \"...\\n\")\n",
    "\n",
    "# Phase 3: Report Generation (reuses Phase 1 & 2)\n",
    "report_prompt = \"\"\"\n",
    "**PRIORITY: Use Phase 1 & 2 findings from conversation memory.**\n",
    "\n",
    "You have:\n",
    "- Phase 1: All revenue calculations and trends\n",
    "- Phase 2: Three visualization charts created\n",
    "\n",
    "**DO NOT re-analyze data.** Use conversation context.\n",
    "\n",
    "Task: Generate executive summary report:\n",
    "1. Key findings (3-5 bullet points)\n",
    "2. Top product recommendation\n",
    "3. Regional strategy suggestion\n",
    "4. Note which charts support each finding\n",
    "\n",
    "Format as markdown.\n",
    "\"\"\"\n",
    "\n",
    "print(\"[Phase 3: Report Generation]\")\n",
    "start = time.time()\n",
    "report_result, _ = client.chat_continue(MODEL, wf_session, report_prompt)\n",
    "print(f\"Time: {time.time() - start:.1f}s\")\n",
    "print(\"\\nExecutive Summary:\")\n",
    "print(report_result)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"✅ 3-phase workflow complete!\")\n",
    "print(\"✅ File processed once in Phase 1\")\n",
    "print(\"✅ Phases 2-3 reused conversation memory\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up test files\n",
    "Path(csv_path).unlink(missing_ok=True)\n",
    "print(f\"✓ Cleaned up {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Summary: Best Practices\n",
    "\n",
    "### ✅ DO:\n",
    "- Process files ONCE in Phase 1\n",
    "- Store findings in conversation memory\n",
    "- Use explicit \"PRIORITY: Use Phase X findings\" instructions\n",
    "- Attach files as fallback reference only\n",
    "- Summarize what previous phases calculated\n",
    "\n",
    "### ❌ DON'T:\n",
    "- Re-upload and re-process files in every phase\n",
    "- Assume the AI will automatically reuse context without instruction\n",
    "- Mix file processing with follow-up questions in the same prompt\n",
    "\n",
    "### Pattern Structure:\n",
    "```\n",
    "Phase 1: \"Analyze file and calculate X, Y, Z\"\n",
    "         ↓ (file processed, results in conversation)\n",
    "         \n",
    "Phase 2: \"PRIORITY: Use Phase 1 findings (X, Y, Z from memory)\"\n",
    "         \"DO NOT re-analyze file\"\n",
    "         \"Task: Generate visualizations\"\n",
    "         ↓ (uses conversation memory, no file re-processing)\n",
    "         \n",
    "Phase 3: \"PRIORITY: Use Phase 1 & 2 findings\"\n",
    "         \"Task: Create report\"\n",
    "         ↓ (uses conversation memory)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**See also:**\n",
    "- [PPTX_Report_Generator_Agent_v2.ipynb](PPTX_Report_Generator_Agent_v2.ipynb) - Full PowerPoint generation example\n",
    "- [CLAUDE.md](CLAUDE.md) - Architecture documentation\n",
    "- Backend code: `backend/utils/phase_manager.py`, `backend/tasks/react/context_manager.py`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
